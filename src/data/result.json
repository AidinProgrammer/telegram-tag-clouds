{
 "name": "CUDA",
 "type": "private_supergroup",
 "id": 1479192468,
 "messages": [
  {
   "id": -998272919,
   "type": "service",
   "date": "2019-05-11T17:08:07",
   "actor": "Aidin Noori",
   "actor_id": "user57661101",
   "action": "join_group_by_link",
   "inviter": "Group",
   "text": ""
  },
  {
   "id": -998272894,
   "type": "service",
   "date": "2019-05-11T17:13:28",
   "actor": "Amir",
   "actor_id": "user599469743",
   "action": "join_group_by_link",
   "inviter": "Group",
   "text": ""
  },
  {
   "id": -998272365,
   "type": "service",
   "date": "2019-05-11T22:37:26",
   "actor": "Fatima",
   "actor_id": "user116344054",
   "action": "join_group_by_link",
   "inviter": "Group",
   "text": ""
  },
  {
   "id": -998272304,
   "type": "service",
   "date": "2019-05-12T04:37:08",
   "actor": "Movahhed R",
   "actor_id": "user105770407",
   "action": "join_group_by_link",
   "inviter": "Group",
   "text": ""
  },
  {
   "id": -998271792,
   "type": "service",
   "date": "2019-05-12T14:24:08",
   "actor": "Hamid Khorshidian",
   "actor_id": "user121569222",
   "action": "migrate_to_supergroup",
   "text": ""
  },
  {
   "id": 1,
   "type": "service",
   "date": "2019-05-12T14:24:08",
   "actor": "CUDA",
   "actor_id": "channel1479192468",
   "action": "migrate_from_group",
   "title": "CUDA",
   "text": ""
  },
  {
   "id": 3,
   "type": "message",
   "date": "2019-05-12T15:00:04",
   "edited": "2019-05-12T21:30:34",
   "from": "Aidin Noori",
   "from_id": "user57661101",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\nکودا (CUDA) که مخفف عبارت انگلیسی Compute Unified Device Architecture است در نوامبر ۲۰۰۶ توسط انویدیا معرفی شد. کودا یک پلتفرم محاسبات موازی همه منظوره و مدل برنامه‌نویسی است که رابط‌های برنامه‌نویسی را در اختیار برنامه‌نویسان قرار داده و به طراحان نرم‌افزار اجازه می‌دهد تا از توانایی‌های جی پی یو GPU در جهت محاسبات همه منظوره روی واحد پردازش گرافیکی استفاده کنند. پلتفرم كودا، یک لایه نرم‌افزاری است که دسترسی مستقیم به مجموعه دستورالعمل‌های مجازی جی پی یو و عناصر محاسبات موازی را می‌دهد. این پلتفرم به گونه‌ای طراحی شده است که با زبان‌های برنامه‌نویسی سی، سی پلاس پلاس، فرترن و متلب کار می‌کند. این قابلیت دسترسی، کار را برای متخصصان برنامه‌نویسی موازی به منظور استفاده از منابع جی پی یو به همان شکلی که از دایرکت ایکس یا اپن جی ال استفاده می‌کنند، هموار کرده است. کودا همچنین از چارچوب‌های برنامه‌نویسی از قبیل OpenACC و OpenCL پشتیبانی می‌کند."
   ]
  },
  {
   "id": 5,
   "type": "message",
   "date": "2019-05-12T19:21:09",
   "edited": "2019-05-12T21:31:19",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\nمدل کودا و نرم افزارهای مرتبط آن با چندین هدف طراحی شده است:\n\n☑️  افزودن توزیع های کوچکی به زبانهای برنامه نویسی استاندارد (مانند سی) که پیاده سازی بی واسطه الگوریتم های موازی را ممکن می سازد. منظور از پیاده سازی بی واسطه، کاهش لایه های واسط بین سخت افزار و نرم افزار است. با کودا و زبان سی برای کودا، برنامه نویسان به جای آن که درگیر پیچیدگی های پیاده سازی شوند، می توانند بر الگوریتم های موازی سازی تمرکز داشته باشند.\n\n☑️  پشتیبانی از پردازش ناهمگن، به نحوی که برنامه ها هم از سی پی یو و هم جی پی یو بهره می برند. بخش های متوالی یا سریال برنامه توسط سی پی یو و بخش های موازی توسط جی پی یو اجرا می شوند. در عمل سی پی یو و جی پی یو واحدهای مجزایی خواهند بود که حافظه جداگانه خود را دارند. این پیکربندی اجازه میدهد تا پردازش همزمان در هر یک از دو واحد، بدون تداخل صورت گیرد.\n\n☑️ در صنعت بازی نیز جی پی یوها در محاسبات فیزیکی بازی استفاده می شوند. از کودا نیز در این زمینه استفاده می شود. \n\nهدف کودا در برنامه های \"متمرکز بر داده\" که نیازمند ریاضیات با ممیز  شناور و دقت معمولی هستند (عمدتأ علمی، مهندسی و محاسبات با کارایی بالا مانند برنامه های ویرایش عکس و فیلم ) خلاصه شده است. ممیز شناور با دقت مضاعف طرح انویدیا برای جی پی یوهای جدید است."
   ]
  },
  {
   "id": 8,
   "type": "message",
   "date": "2019-05-12T20:25:26",
   "edited": "2019-05-12T21:31:55",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 684,
   "height": 337,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n✅  بین معماری سی پی یوها و جی پی یوها تفاوت های اساسی زیادی وجود دارد. در سی پی یوها یک و یا تعداد اندکی هسته وجود دارد که هر هسته بار محاسباتی زیادی را انجام می دهد، اما در معماری جی پی یو، هزاران هسته محاسباتی وجود دارد که عمدتا این هسته ها به طور موازی قسمت هایی از برنامه را اجرا می کنند. به عبارت دیگر  در معماری جی پی یو می توان این شکل را متصور شد که به جای یک سی پی یو با چهار هسته و یک واحد کنترل و کش و یک داینامیک رم، صدها هسته داریم که کارهای بسیار ساده ای انجام میدهند. در واقع هرچند هسته، یک مالتی پروسسور را تشکیل میدهند که هر کدام از آنها دارای حافظه اختصاصی از جمله حافظه اشتراکی و حافظه لوکال و ثبات هستند. همچنین هر مالتی پروسسور دارای یک کنترلر و یک داینامیک رم می باشد که در عمل از آن به عنوان ورودی و خروجی کرنل ( توابعی که در جی پی یو  اجرا می شوند ) استفاده می شود."
   ]
  },
  {
   "id": 9,
   "type": "message",
   "date": "2019-05-12T21:31:53",
   "from": "Hossein Razavi",
   "from_id": "user571362746",
   "text": "سلام \nچطور میتونم مشخصات GPU خودمو مثل تعداد تردهای یک بلاک یا تعداد بلاک هارو تو لینوکس ببینم؟"
  },
  {
   "id": 10,
   "type": "service",
   "date": "2019-05-12T21:40:34",
   "actor": "siavash baratian",
   "actor_id": "user392846334",
   "action": "join_group_by_link",
   "inviter": "Group",
   "text": ""
  },
  {
   "id": 12,
   "type": "message",
   "date": "2019-05-12T21:49:19",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 9,
   "text": "سلام . اگه  sample های خود کودا  رو نصب کرده باشی  یک  پوشه  device Query  تو sample ها هست. که تو اون پوشه ترمینال باز کنی بعد دستور  make -k  بزنی  یک فایل اجرایی می سازه . بعد اون فایل رو اجرا بگیری میتونی مشخصات GPU  رو ببینی."
  },
  {
   "id": 15,
   "type": "message",
   "date": "2019-05-12T21:58:51",
   "from": "Hossein Razavi",
   "from_id": "user571362746",
   "reply_to_message_id": 12,
   "text": "🙏🌺 \nدستت درد نکنه 👍"
  },
  {
   "id": 28,
   "type": "message",
   "date": "2019-05-13T22:16:04",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 715,
   "height": 535,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🔘 روند پردازش کودا\n\n1️⃣ انتقال  داده به حافظه GPU  \n\n2️⃣ انتقال دستورالعمل از CPU به GPU\n\n3️⃣ پردازش موازی در GPU\n\n4️⃣ انتقال نتیجه به حافظه اصلی"
   ]
  },
  {
   "id": 29,
   "type": "message",
   "date": "2019-05-13T22:16:20",
   "from": "Ghzsal",
   "from_id": "user344760551",
   "reply_to_message_id": 28,
   "text": "👍👍👍👍"
  },
  {
   "id": 30,
   "type": "message",
   "date": "2019-05-13T22:24:23",
   "from": "Aidin Noori",
   "from_id": "user57661101",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "sticker",
   "sticker_emoji": "👍",
   "width": 512,
   "height": 512,
   "text": ""
  },
  {
   "id": 31,
   "type": "message",
   "date": "2019-05-13T22:37:07",
   "edited": "2019-05-13T22:40:18",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 579,
   "height": 641,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n✔️ سطوح دسترسی واحدهای مختلف در جی پی یو به منابع حافظه مطابق زیر است :\n\n1️⃣ در سطح یک نخ :  هر نخ می تواند به صورت اختصاصی به یک سری رجیستر که به صورت onchip هستند  و local memory که به صورت off-chip و uncached هستند، دسترسی داشته باشد.\n\n2️⃣ در سطح بلاک : هر بلاک از چندین نخ تشکیل شده، هر بلاک به صورت اختصاصی به یک shared memory که on - chip بوده البته با اندازه کوچک که سرعت بالایی دارد، دسترسی دارد.\n\n3️⃣ در سطح گرید : هر گرید از چندین بلاک تشکیل شده، در سطح گرید، یا به عبارتی در سطح جی پی یو به Global memory که off- chip بوده با سرعت کم ولی با اندازه بزرگ، دسترسی دارد. از Global memory به خاطر سرعت کم آن بیشتر به عنوان ورودی و خروجی کرنل ها استفاده می شود."
   ]
  },
  {
   "id": 39,
   "type": "message",
   "date": "2019-05-14T15:17:01",
   "from": "Amir",
   "from_id": "user599469743",
   "text": "سلام دوستان چطور می تونم تو لینوکس بفهمم برنامه ایی که نوشتم واقعا توسط GPU اجرا میشه؟؟"
  },
  {
   "id": 42,
   "type": "message",
   "date": "2019-05-14T17:07:47",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 39,
   "text": "سلام . وقتی برنامت در حال اجرست یک ترمینال باز کن و دستور nvidia-smi رو بزن. میتونی لیست برنامه هایی که gpu داره اجرا میکنه رو ببینی و اینکه میتونی همونجا memory-usage رو هم ببینی."
  },
  {
   "id": 43,
   "type": "service",
   "date": "2019-05-14T17:51:49",
   "actor": "M Sadeghi",
   "actor_id": "user119511961",
   "action": "join_group_by_link",
   "inviter": "Group",
   "text": ""
  },
  {
   "id": 44,
   "type": "message",
   "date": "2019-05-14T18:05:16",
   "from": "Amir",
   "from_id": "user599469743",
   "reply_to_message_id": 42,
   "text": "🙏👌"
  },
  {
   "id": 45,
   "type": "message",
   "date": "2019-05-14T19:29:31",
   "from": "Ghzsal",
   "from_id": "user344760551",
   "reply_to_message_id": 42,
   "text": "🙏🙏🙏🙏🙏🙏"
  },
  {
   "id": 51,
   "type": "message",
   "date": "2019-05-17T15:13:18",
   "edited": "2019-05-17T15:20:33",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    " \n\n🔍 تابع ()malloc  \n\nنام malloc مخفف \"memory allocation\" است. تابع ()malloc یک بلوک از حافظه با سایز و اندازه مشخص رزرو کرده و در صورت موفقیت یک اشاره گر از نوع void به اولین بایت بلوک حافظه برگردانده و در صورت شکست یک اشاره گر NULL برمی گرداند. اشاره گر از نوع void این تابع برای از مرجع خارج کردن یا dereference آن، می تواند به اشاره گر با نوع دلخواه قالب بندی یا اصطلاحا cast شود.\n\n🔗  ptr = (cast - type*) malloc(byte-size) \n\nبرای مثال اینجا، ptr یک اشاره گر از نوع قالب موردنظر یا cast- type است. تابع () malloc اشاره گر به محلی از حافظه با سایز و اندازه تعیین شده به بایت برمی گرداند. اگر فضای حافظه کافی نباشد، عملیات تخصیص شکست یافته یا اصطلاحا fail می شود و یک اشاره گر NULL برمی گرداند.\n\n🖍 استفاده از دستور malloc  برای تخصیص حافظه در فایل کتابخانه ای ( هدر فایل ) stdlib.h  تعریف شده است."
   ]
  },
  {
   "id": 52,
   "type": "message",
   "date": "2019-05-17T15:37:09",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "reply_to_message_id": 51,
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "sticker",
   "sticker_emoji": "👍",
   "width": 512,
   "height": 512,
   "text": ""
  },
  {
   "id": 53,
   "type": "message",
   "date": "2019-05-17T15:40:54",
   "from": "Reza Shaygan",
   "from_id": "user237786821",
   "reply_to_message_id": 51,
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "sticker",
   "sticker_emoji": "😐",
   "width": 512,
   "height": 512,
   "text": ""
  },
  {
   "id": 54,
   "type": "message",
   "date": "2019-05-17T15:44:39",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1024,
   "height": 1024,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nThe Aorus GeForce RTX 2080. Beastly power, 3 fans, and overlocking tools to help you crank your games to Ultra. Available now with a discount + rebate 💲💲  ",
    {
     "type": "link",
     "text": "https://t.co/mvADwAu1e8"
    },
    "  💲💲"
   ]
  },
  {
   "id": 55,
   "type": "message",
   "date": "2019-05-17T16:16:21",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "reply_to_message_id": 54,
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "sticker",
   "sticker_emoji": "👍",
   "width": 512,
   "height": 512,
   "text": ""
  },
  {
   "id": 56,
   "type": "message",
   "date": "2019-05-17T16:17:16",
   "from": "Reza Shaygan",
   "from_id": "user237786821",
   "reply_to_message_id": 54,
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "sticker",
   "sticker_emoji": "👌",
   "width": 512,
   "height": 512,
   "text": ""
  },
  {
   "id": 60,
   "type": "message",
   "date": "2019-05-18T01:19:10",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "video_file",
   "mime_type": "video/mp4",
   "duration_seconds": 48,
   "width": 854,
   "height": 480,
   "text": ""
  },
  {
   "id": 61,
   "type": "message",
   "date": "2019-05-18T01:20:48",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "text": "تاثیر مثبت گیمیر ها در بهبود GPU ها که باعث شدن مسالی که نیمشد قبلا حلش کردرو درش تجدید نظر کنن"
  },
  {
   "id": 62,
   "type": "message",
   "date": "2019-05-18T01:21:14",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "via_bot": "@gif",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "animation",
   "mime_type": "video/mp4",
   "duration_seconds": 2,
   "width": 480,
   "height": 480,
   "text": ""
  },
  {
   "id": 63,
   "type": "message",
   "date": "2019-05-18T01:21:35",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "via_bot": "@gif",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "animation",
   "mime_type": "video/mp4",
   "duration_seconds": 3,
   "width": 480,
   "height": 362,
   "text": ""
  },
  {
   "id": 64,
   "type": "message",
   "date": "2019-05-18T01:21:40",
   "from": "Reza Shaygan",
   "from_id": "user237786821",
   "reply_to_message_id": 61,
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "sticker",
   "sticker_emoji": "👍",
   "width": 512,
   "height": 512,
   "text": ""
  },
  {
   "id": 66,
   "type": "message",
   "date": "2019-05-18T01:25:14",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "reply_to_message_id": 64,
   "text": "👍"
  },
  {
   "id": 67,
   "type": "message",
   "date": "2019-05-18T01:35:46",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "text": [
    {
     "type": "link",
     "text": "https://www.youtube.com/watch?v=OTOGw0BRqK0"
    }
   ]
  },
  {
   "id": 68,
   "type": "service",
   "date": "2019-05-18T12:02:13",
   "actor": "Shokrani",
   "actor_id": "user286512463",
   "action": "join_group_by_link",
   "inviter": "Group",
   "text": ""
  },
  {
   "id": 70,
   "type": "service",
   "date": "2019-05-22T12:07:13",
   "actor": "Shokrani",
   "actor_id": "user286512463",
   "action": "join_group_by_link",
   "inviter": "Group",
   "text": ""
  },
  {
   "id": 74,
   "type": "message",
   "date": "2019-05-23T23:46:07",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🔎 کرنل ها و ویژگی مربوط به آنها\n\nکرنل در واقع همان تابع زبان سی است که از آن خواسته می شود که به صورت موازی اجرا شود، نخها در جی پی یو به صورت کار می کنند. یعنی همه نخ ها به صورت همزمان با هم یک دستور یکسان را روی چندین داده متفاوت اجرا می کنند، پس منظور از اجرای موازی برنامه این است که بعد از فراخوانی کرنل به تعداد نخهای تعیین شده از برنامه کپی شده و به هر نخ یک کپی از آن داده می شود تا بسته به ماهیت برنامه و ابعاد موردنیاز آن، با اعمال مؤلفه های X و Y و Z برای هر نخ که توسط کاربر صورت می گیرد، دستور یا عملیات موردنظر مثلا جمع یا ضرب انجام شود. در موقع فراخوانی کرنل از <<< , >>> برای تعیین تعداد بلاک های موجود در گرید و نخ های داخل بلاک استفاده می شود که آرگومان اول بیانگر تعداد بلاک ها در گرید و آرگومان دوم تعداد نخها در بلاک است.\n\n🔔 یاد آوری : به صورت سلسله مراتب مجموعه ای از نخ ها یک بلاک را تشکیل داده و مجموعه ای از بلاک ها یک گرید را تشکیل میدهند.\n\n 💣 به عنوان مثال  قطعه کد زیر از 1 بلاک و N  نخ استفاده شده است.\n\n//Kernel definition\nglobal void VecAdd(float* A, float* B, float* C)\n{\n     ....\n}\nint main()\n{\n    ...\n// Kernel invocation\nVecAdd < < < 1, N > > >(A, B, C);\n}"
   ]
  },
  {
   "id": 75,
   "type": "message",
   "date": "2019-05-23T23:46:26",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🔍 کرنل ها و ویژگی مربوط به آنها\n\nبرای تعریف کرنل مانند تعریف تابع در زبان سی عمل می کنیم با سه تفاوت اصلی:\n\n1️⃣ این تابع هیچ گونه خروجی نخواهد داشت و نوع بازگشتی آن باید از نوع void باشد.\n\n2️⃣ در ابتدای تابع از کلمه کلیدی global استفاده می شود.\n\n3️⃣ ورودی های این تابع باید به صورت اشاره گر تعریف شوند (اشاره گرهایی که به حافظه گلوبال اشاره می کنند)."
   ]
  },
  {
   "id": 76,
   "type": "message",
   "date": "2019-05-23T23:46:31",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1207,
   "height": 406,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    " \n\n📣📣  توجه 📣📣\n  هنگامی که با استفاده از دستور <<< >>> یک کرنل را فراخوانی می کنیم به طور خودکار توسط کامپایلر کودا یک متغیر از نوع dim3 تعریف شده که تعداد بلاکها در هر گرید و نخها در هر بلاک را مشخص می کند. منظور از این جمله این است که حتی اگر گرید و بلاک را به صورت یک بعدی (تعیین مولفه X) هم تعریف کنیم کودا آن را به صورت یک متغیر dim3 می شناسد و برای ابعاد y   و  z آن مقدار 1   قرار میدهد."
   ]
  },
  {
   "id": 77,
   "type": "message",
   "date": "2019-05-23T23:46:35",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\nint main()\n{\n\n// Kernel invocation with N threads \ndim3 dimBlock(50, 100); \ndim3 dimGrid(20, 25); \nVecAdd << <dimGrid, dimBlock >> >(A, B, C);\n ....\n\n}\n\nتوجه داشته باشید که dim3 بیانگر سه بعدی بودن نوع تعریف برای بلاک ها و گریدها بوده و دارای مؤلفه های x و y و z برای هر یک از آنان است و استفاده از این نوع داده داخلی کودا برای بلاک ها، ابعاد بلاک را مشخص کرده و تعداد نخ های داخل بلاک (توسط حاصل ضرب مؤلفه های x و y و z ) را مشخص می کند. اگر ابعاد گریدها و بلاک های ما بیش از یک بعد باشد بهتر است برای بیان بعد دوم (یعنی ) و در صورت لزوم بعد سوم (یعنی z) از نوع داده داخلی کودا dimn3 در تعریف استفاده کنیم، به طور مثال (50  ,dimBlock (100 بیانگر 100 * 50 یا 500 نخ در داخل بلاک است (مقدار x در اینجا 50 و مقدار y برابر 100 و مقدار z چون ذکر نشده در اینجا 1 است).\nاستفاده از dim3 برای گرید، ابعاد گرید را مشخص کرده و تعداد بلاک های داخل گرید (توسط حاصل ضرب مولفه های x و  y  و z ) را مشخص می کند. \nبنابراین ( 25 ,20)dimGrid بیانگر 25 * 20 یا 500 بلاک در داخل گرید است (مقدار X در اینجا 20 و مقدار y برابر 25 و مقدار z چون ذکر نشده در اینجا 1 است .\nحداکثر مقدار بلاک در داخل گرید بستگی به نوع کارت گرافیک و قابلیت محاسباتی آن داشته و حداکثر این مقدار معمولا 1024 بلاک در گرید می باشد."
   ]
  },
  {
   "id": 78,
   "type": "message",
   "date": "2019-05-24T00:02:06",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "sticker",
   "sticker_emoji": "👍",
   "width": 512,
   "height": 512,
   "text": ""
  },
  {
   "id": 79,
   "type": "message",
   "date": "2019-05-24T15:21:48",
   "edited": "2019-05-24T15:22:31",
   "from": "Ali Farjad( );",
   "from_id": "user66223598",
   "text": [
    "سلام دوستان\nتوی اجرای پروژه ای که استاد (comd) دادن به خطای زیر خوردم\n\n",
    {
     "type": "pre",
     "text": "content/comd/src/src-mpi/eam.c:287: undefined reference to `lunch_eamForce_kernel",
     "language": ""
    },
    ""
   ]
  },
  {
   "id": 80,
   "type": "message",
   "date": "2019-05-24T15:22:17",
   "from": "Ali Farjad( );",
   "from_id": "user66223598",
   "text": "تابع هایی که داخل فایل .cu مربوطه تعریف شده رو پیدا نمی کنه...\nراه حلی سراغ دارید.\nممنون"
  },
  {
   "id": 81,
   "type": "message",
   "date": "2019-05-24T15:55:29",
   "edited": "2019-05-24T15:55:43",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 80,
   "text": "سلام اگه ممکن یک اطلاعاتی مثل نسخه کودا و  محیط اجرا بده. یا یک اسکرین بذار."
  },
  {
   "id": 82,
   "type": "message",
   "date": "2019-05-24T16:55:29",
   "from": "Ali Farjad( );",
   "from_id": "user66223598",
   "text": "روی گوگل کولب آخرین نسخه کودا"
  },
  {
   "id": 83,
   "type": "message",
   "date": "2019-05-24T18:27:49",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "reply_to_message_id": 82,
   "text": "نسخه 10 هست"
  },
  {
   "id": 84,
   "type": "message",
   "date": "2019-05-24T19:24:54",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 79,
   "text": [
    {
     "type": "link",
     "text": "https://stackoverflow.com/questions/13553015/cuda-c-linker-error-undefined-reference"
    }
   ]
  },
  {
   "id": 85,
   "type": "message",
   "date": "2019-05-24T19:26:23",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 84,
   "text": "دوستان  کسی روی colab تست کرده  این مورد رو؟؟؟"
  },
  {
   "id": 119,
   "type": "service",
   "date": "2019-06-20T09:49:24",
   "actor": null,
   "actor_id": "user565624175",
   "action": "join_group_by_link",
   "inviter": "Group",
   "text": ""
  },
  {
   "id": 121,
   "type": "message",
   "date": "2019-06-20T15:04:30",
   "from": "Aidin Noori",
   "from_id": "user57661101",
   "text": [
    {
     "type": "link",
     "text": "https://www.youtube.com/watch?v=srrDmXMb6Kw"
    }
   ]
  },
  {
   "id": 124,
   "type": "service",
   "date": "2019-07-01T21:38:18",
   "actor": null,
   "actor_id": "user552249431",
   "action": "join_group_by_link",
   "inviter": "Group",
   "text": ""
  },
  {
   "id": 128,
   "type": "message",
   "date": "2019-07-05T23:50:11",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "forwarded_from": "Zoomit | زومیت",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 750,
   "height": 375,
   "text": [
    "🔔 فیس تایم در iOS 13 زاویه دید کاربر را حین تماس ویدیویی اصلاح می‌کند\n\nاپل به‌تازگی از ویژگی جدیدی در نسخه بتای ios 13 رونمایی کرده که در آن باکمک ARKit3، زاویه دید مخاطب حین مکالمه ویدئویی تصحیح می‌شود.\n\nدر زومیت بخوانید:\n📎 ",
    {
     "type": "link",
     "text": "http://bit.ly/2RQYKQr"
    },
    "\n\n",
    {
     "type": "mention",
     "text": "@myzoomit"
    },
    ""
   ]
  },
  {
   "id": 152,
   "type": "message",
   "date": "2019-07-10T09:40:54",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "video_file",
   "mime_type": "video/mp4",
   "duration_seconds": 80,
   "width": 640,
   "height": 360,
   "text": [
    "NVIDIA GeForce\nThe GeForce RTX 2070 and 2060 SUPER are now available! \n\n✅ Improved performance\n\n✅ Ray-Tracing \n\n✅ DLSS \n\n✅ Next-Gen Shading Gear Up and Get Superpowers → ",
    {
     "type": "link",
     "text": "https://t.co/5TZihKtPW5"
    },
    ""
   ]
  },
  {
   "id": 153,
   "type": "message",
   "date": "2019-07-10T10:03:05",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n☑️ مفهوم gridDim: از نوع dim3 (سه بعدی و دارای مؤلفه های x و y و z) بوده و ابعاد گرید رامشخص می کند. به عبارت دیگر این نوع داده داخلی کودا، تعداد بلاک های داخل گرید را ( با حاصل ضرب مؤلفه های x و y و z درهم) تعیین می کند.\n\n☑️ مفهوم blockIdx : از نوع uint3 (نوع دادهای آن، عدد صحیح بدون علامت و دارای سه مؤلفه X و y و  z) بوده و بیان کننده اندیس یا شماره بلاک موجود در درون گرید است.\n\n☑️ مفهوم blockDim : از نوع dim3 (سه بعدی و دارای مؤلفه های x و y و z) بوده و ابعاد بلاک را مشخص می کند. در واقع این نوع داده داخلی کودا، تعداد نخهای داخل بلاک را (توسط حاصل ضرب مؤلفه های x و y و z درهم) تعیین می کند."
   ]
  },
  {
   "id": 154,
   "type": "message",
   "date": "2019-07-10T10:22:33",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1063,
   "height": 493,
   "text": [
    {
     "type": "bold",
     "text": "GET SUPER POWERS"
    },
    "\nNow the new GeForce RTX SUPER™ Series has even more cores and higher clocks, bringing you performance that’s up to 25% faster than the original RTX 20 Series. It’s time to gear up and get super powers."
   ]
  },
  {
   "id": 181,
   "type": "message",
   "date": "2019-07-10T19:25:13",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 325,
   "height": 309,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\nدر برنامه نویسی با کودا اولین نکته، دستور ساخت نخ است. وظیفه ی ساخت نخ با برنامه نویس است و برنامه نویس باید تشخیص دهد که چند نخ باید ساخته شود، در حقیقت در ابتدای حل هر مسئله، باید استراتژی موازی سازی مشخص شود که چند نخ ایجاد شود و هر نخ باید چه عملی را انجام دهد. البته  باید توجه داشت منظور  از ساخت نخ به صورت نرم افزاری است که همان طور که گفته شد مجموعه ای از این نخها کنار هم بلاک را تشکیل داده و آنها هم نهایتا گرید را تشکیل میدهند و با معانی آنها به صورت سخت افزاری فرق دارند. مثلا معادل آنها در سطح سخت افزاری جی پی یو، پردازنده نخ و مالتی پروسسور و دیوایس هستند."
   ]
  },
  {
   "id": 182,
   "type": "message",
   "date": "2019-07-10T19:25:13",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1280,
   "height": 622,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\nهویت سراسری هر نخ با فرمولی بسیار ساده به دست می آید.  برای مثال می خواهیم هویت سراسری نخ سوم که مقدار آن 2 است) در بلاک شماره چهارم (3=blockldx.x ) را محاسبه کنیم که از حاصل ضرب blockldx . x و blockDim . x بعلاوه threadIdx . x  در واقع 2+ 8*3 به دست می آید که برابر با 26 است. پس در حقیقت هویت سراسری یا Global ID آن نخ برابر با 26 است. پس می توانیم بگوییم که اندیس این نخ در حافظه گلوبال برابر با 26 است."
   ]
  },
  {
   "id": 183,
   "type": "message",
   "date": "2019-07-10T20:16:29",
   "from": "Aidin Noori",
   "from_id": "user57661101",
   "text": "👌🏼👌🏼 عالی"
  },
  {
   "id": 184,
   "type": "message",
   "date": "2019-07-11T23:07:41",
   "from": "Saeide Pourhasan",
   "from_id": "user91119609",
   "text": [
    {
     "type": "link",
     "text": "https://www.instagram.com/p/Bzw7Wu8gp4f/?igshid=2v0n20vlm5og"
    }
   ]
  },
  {
   "id": 185,
   "type": "message",
   "date": "2019-07-11T23:14:07",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 184,
   "text": "بسیار عالی👌"
  },
  {
   "id": 186,
   "type": "message",
   "date": "2019-07-11T23:14:22",
   "from": "Ghzsal",
   "from_id": "user344760551",
   "reply_to_message_id": 184,
   "text": "🙏🙏🙏🙏"
  },
  {
   "id": 187,
   "type": "message",
   "date": "2019-07-11T23:15:23",
   "from": "Saeide Pourhasan",
   "from_id": "user91119609",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "sticker",
   "sticker_emoji": "🌷",
   "width": 512,
   "height": 512,
   "text": ""
  },
  {
   "id": 189,
   "type": "message",
   "date": "2019-07-12T12:21:40",
   "from": "Aidin Noori",
   "from_id": "user57661101",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1024,
   "height": 512,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nNGC is the hub for GPU-optimized software AI and HPC allowing data scientists, developers, and researchers to focus on building solutions, gathering insights, and delivering business value. ",
    {
     "type": "link",
     "text": "https://nvda.ws/2O5Qr1e"
    }
   ]
  },
  {
   "id": 190,
   "type": "message",
   "date": "2019-07-12T17:30:03",
   "from": "Aidin Noori",
   "from_id": "user57661101",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1024,
   "height": 512,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nThe Tohoku Medical Megabank Organization is using the ddn_limitless A3I DGXPOD solution to increase their supercomputing capacity to accelerate genomic research. \nLearn more: ",
    {
     "type": "link",
     "text": "https://nvda.ws/2JB2i5B"
    }
   ]
  },
  {
   "id": 191,
   "type": "message",
   "date": "2019-07-12T19:35:29",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "text": [
    {
     "type": "link",
     "text": "https://vmmax2.site/order?ref=3427673"
    }
   ]
  },
  {
   "id": 192,
   "type": "message",
   "date": "2019-07-12T22:02:57",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "text": [
    {
     "type": "link",
     "text": "https://www.slideshare.net/NVIDIA/top-5-deep-learning-and-ai-stories-october-6-2017-80543540"
    }
   ]
  },
  {
   "id": 193,
   "type": "message",
   "date": "2019-07-13T02:27:01",
   "from": "Ghzsal",
   "from_id": "user344760551",
   "reply_to_message_id": 192,
   "text": "🙏🙏🙏🙏🙏🙏🙏"
  },
  {
   "id": 194,
   "type": "message",
   "date": "2019-07-14T00:14:03",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1280,
   "height": 501,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n",
    {
     "type": "bold",
     "text": "🖊تخصیص اندیس ها در بلاک و گرید\n\n"
    },
    "🔍گرید یک بعدی شامل بلاک های یک بعدی\n\nبرای تنظیم این نوع اندیس دهی به صورت زیر عمل می کنیم.\nint index = blockIdx.x * blockDim.x + threadIdx.x ;"
   ]
  },
  {
   "id": 195,
   "type": "message",
   "date": "2019-07-14T00:14:03",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1280,
   "height": 609,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n",
    {
     "type": "bold",
     "text": "🖊تخصیص اندیس ها در بلاک و گرید\n\n"
    },
    "🔍گرید یک بعدی شامل بلاک های دو بعدی\n\nبرای تنظیم این نوع اندیس دهی به صورت زیر عمل می کنیم.\nint index = blockIdx.x * blockDim.x * blockDim.y + threadIdx.y * blockDim.x  + threadIdx.x ;"
   ]
  },
  {
   "id": 196,
   "type": "message",
   "date": "2019-07-14T00:14:03",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n",
    {
     "type": "bold",
     "text": "🖊تخصیص اندیس ها در بلاک و گرید\n\n"
    },
    "🔍گرید دو بعدی شامل بلاک های یک بعدی\n\nبرای تنظیم این نوع اندیس دهی به صورت زیر عمل می کنیم.\n\nint blockId = blockIdx.y * gridDim.x + blockIdx.x ;\nint threadId = blockId * blockDim.x + threadIdx.x;"
   ]
  },
  {
   "id": 197,
   "type": "message",
   "date": "2019-07-14T00:14:03",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n",
    {
     "type": "bold",
     "text": "🖊تخصیص اندیس ها در بلاک و گرید\n\n"
    },
    "🔍گرید دو بعدی شامل بلاک های دو بعدی\n\nبرای تنظیم این نوع اندیس دهی به صورت زیر عمل می کنیم.\n\nint blockId = blockIdx.y * gridDim.x + blockIdx.x ;\nint threadId = blockId * (blockDim.x * blockDim.y) + (threadIdx.y * blockDim.x) + threadIdx.x ;"
   ]
  },
  {
   "id": 198,
   "type": "message",
   "date": "2019-07-14T00:14:19",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "text": "👍"
  },
  {
   "id": 204,
   "type": "message",
   "date": "2019-07-18T00:40:23",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🖍  کنترل خطا در کودا\n\n🔗  دو منشأ بروز خطا در سورس کودا وجود دارد.\n\n1️⃣  خطاهایی از فرخوانی توابع API کودا، برای مثال، یک فراخوانی ()cuda Malloc ممکن است با شکست مواجه شود. \n2️⃣  خطاهایی از فراخوانی کرنل کودا، برای مثال ممکن است دستیابی به حافظه در یک کرنل نامعتبر باشد.\n\nهمه فرخوانی های توابع API کودا یک مقدار CudaError_t بر می گردانند، بنابراین این فراخوانی ها برای بررسی خطا ساده می باشند.\n\nif (cudaSuccess != cudaMalloc(&fooptr, foosize))\nprint (\"Error\")"
   ]
  },
  {
   "id": 205,
   "type": "message",
   "date": "2019-07-18T00:41:19",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "reply_to_message_id": 204,
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "sticker",
   "sticker_emoji": "👌",
   "width": 512,
   "height": 512,
   "text": ""
  },
  {
   "id": 212,
   "type": "message",
   "date": "2019-07-18T22:47:27",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🖍  کنترل خطا در کودا\n\nفراخوانی های کرنل کودا هیچ مقداری را بر نمی گردانند. خطای حاصل از فراخوانی یک کرنل کودا می تواند بعد از اجرای آن با فراخواندن ()cudaGetLastError صورت گیرد.\n",
    {
     "type": "bold",
     "text": "cudaError_t cudaGetLastError(void)\n\nfooKernel << < x , y >> >() ; \nif ( cudaSuccess != cudaGetLastError() ) ;\nprintf(\"Error\") ;"
    },
    ""
   ]
  },
  {
   "id": 213,
   "type": "message",
   "date": "2019-07-18T23:41:59",
   "from": "Saeide Pourhasan",
   "from_id": "user91119609",
   "reply_to_message_id": 212,
   "text": "🙏"
  },
  {
   "id": 215,
   "type": "message",
   "date": "2019-07-19T10:24:04",
   "from": "Aidin Noori",
   "from_id": "user57661101",
   "forwarded_from": "CUDA",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "video_file",
   "mime_type": "video/mp4",
   "duration_seconds": 97,
   "width": 1280,
   "height": 720,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nUsing NGC containers, AI startup Neurala achieved 8x speedup for their video annotation tool, Brain Builder. Learn how NGC can accelerate your AI projects today: ",
    {
     "type": "link",
     "text": "https://t.co/hQD2lVGePi"
    }
   ]
  },
  {
   "id": 216,
   "type": "message",
   "date": "2019-07-19T19:57:35",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n📢 یادآوری : با گذاشتن کلمه کلیدی inline قبل از اسم تابع می توانید یک تابع خطی بنویسید که مزیت آن، این است که دیگر کاهش سرعت کامپایل برنامه به خاطر فراخوانی تابع و اجرای تابع را ندارید و مثل ماکرو، هر جا اسمی از آن تابع در برنامه دیده شود، کامپایلر کپی آن تابع را در برنامه قرار میدهد و مثل دستورات عادی داخل برنامه آنها را اجرا می کند. به این صورت سرعت کامپایل برنامه افزایش می یابد و معمولا در شرایطی، استفاده از آن فایده دارد که تعریف تابع، کوتاه است و در چند جای برنامه  قرار است فراخونی شود.\n\n",
    {
     "type": "bold",
     "text": "inline int max (int a , int b) {"
    },
    "\n",
    {
     "type": "bold",
     "text": "return (a >b ? a : b) ;"
    },
    "\n",
    {
     "type": "bold",
     "text": "}"
    },
    "\n\n",
    {
     "type": "bold",
     "text": "int main()"
    },
    " \n",
    {
     "type": "bold",
     "text": "{"
    },
    " \n",
    {
     "type": "bold",
     "text": "cout << \" maximum of 100 & 101 is \" << max (100 , 101) ;"
    },
    "\n",
    {
     "type": "bold",
     "text": "return 0 ;"
    },
    ""
   ]
  },
  {
   "id": 217,
   "type": "message",
   "date": "2019-07-19T20:01:07",
   "from": "Aidin Noori",
   "from_id": "user57661101",
   "text": "👌🏼👌🏼"
  },
  {
   "id": 221,
   "type": "message",
   "date": "2019-07-26T18:40:02",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#اطلاعات_عمومی"
    },
    "\n\n🔔 واحد پردازش تنسور (TPU):  یک نوع مدارمجتمع با کاربرد خاص   (Application-specific integrated circuit) است که توسط گوگل به طور خاص برای کارهای یادگیری ماشین توسعه داده شده اند. در مقایسه با GPUها که در سال‌های اخیر علاوه بر کاربرد اصلی، برای همین نوع مسائل استفاده شده، TPUها برای حجم بالاتر  داده ولی دقیق تر ( مثلا 8 بیتی ) و  کاهش محاسبات طراحی شده اند. \nگوگل ادعا کرده این واحدهای پردازشی تا 10 برابر سریع تر از GPUها برای کارهای یادگیری ماشین هستند. در حال حاضر بسیاری از محصولات گوگل اعم از مترجم و … از این واحد پردازش استفاده می کنند. TPUها می توانند به راحتی عملیات ضرب و جمع حجیم در شبکه های عصبی با سرعت بسیار بالاتر و مصرف انرژی بسیار پایین تری انجام بدهند. در TPU از معماری آرایه سیستولی استفاده می شود. یکی از پرکاربردترین معماری هایی که برای موازی سازی پردازش تصویردر سطح پایین استفاده می شود معماری سیستولیک است و در آن واحدهای پردازشگر معمولا دارای ساختاری ثابت هستند. در ابتدا TPU پارامترها را از حافظه به ماتریس جمع کننده و ضرب کننده انتقال می دهد (عملیات جمع به صورت همزمان انجام می شود). سپس TPU داده ها را از حافظه می خواند. با اجرای هر عملیات ضرب ، نتایج به  ضرب کننده های بعدی منتقل می شود. در حین انجام عملیاتی با این حجم، پردازنده هیچ نیازی به دسترسی به حافظه ندارد."
   ]
  },
  {
   "id": 222,
   "type": "message",
   "date": "2019-07-26T19:08:30",
   "from": "Hossein Razavi",
   "from_id": "user571362746",
   "reply_to_message_id": 221,
   "text": "👌👍"
  },
  {
   "id": 223,
   "type": "message",
   "date": "2019-07-27T15:43:26",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 850,
   "height": 751,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    " \n\n🖋 مدیریت انواع حافظه در کودا \n\n☑️  انواع حافظه ها شامل :\n\n1️⃣ Registers   2️⃣ Global Memory    3️⃣ Texture Memory \n\n4️⃣ Shared Memory     5️⃣ Constant Memory"
   ]
  },
  {
   "id": 224,
   "type": "message",
   "date": "2019-07-27T15:43:26",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🔵 حافظه ثبات یا رجیستر\n\nرجیسترها on-chip هستند. بنابراین تاخیر بسیار اندک و پهنای باند بسیار بالایی دارند. حافظه رجیستر در حقیقت سریع ترین حافظه ممکن است به صورتی که ۱۰ برابر سریع تر از حافظه اشتراکی بوده و ظرفیت آن ۳۲ کیلوبایت است. البته این موارد (سرعت و مقدار ظرفیت) به ویژگی مربوط به دیوایس های مختلف و قابلیت محاسباتی آنها بستگی دارد. اکثر متغیرهای پشته تعریف شده در کرنل ها در رجیسترها ذخیره می شوند به عنوان مثال:  float x یا int x به عبارت دیگر اکثر  متغیرهایی که به این صورت تعریف شوند، در رجیسترها قرار می گیرند. علاوه بر این آرایه های با اندیس های ثابت روی پشته، بعضی مواقع در رجیسترها قرار می گیرند. دامنه رجیسترها فقط در سطح نخ ها بوده و فقط توسط یک نخ قابل دسترسی هستند و هر نخ می تواند در حافظه رجیستر بخواند و بنویسد، به عبارت دیگر زمان حیات رجیسترها تنها در داخل نخ هاست."
   ]
  },
  {
   "id": 225,
   "type": "message",
   "date": "2019-07-27T16:51:51",
   "edited": "2019-07-27T16:52:05",
   "from": "Saeide Pourhasan",
   "from_id": "user91119609",
   "reply_to_message_id": 224,
   "text": "اگر اندازه ثبات ها کافی نباشد ، داده ها به حافظه محلی می روند که باز هم این داده ها برای نخ های دیگر خصوصی هستند، البته این امر باعث میشود سرعت اجرا به طور قابل توجهی کاهش یابد و به همین دلیل تا جایی که امکان دارد باید از سرریز ثبات ها اجتناب شود"
  },
  {
   "id": 226,
   "type": "message",
   "date": "2019-07-27T16:53:30",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 225,
   "text": "👌👌🙏"
  },
  {
   "id": 227,
   "type": "message",
   "date": "2019-07-27T16:59:05",
   "from": "Ali Riahi",
   "from_id": "user73243136",
   "reply_to_message_id": 224,
   "text": "فکر میکنم اگر آرایه ای در داخل کرنل تعریف شود، قطعا در حافظه محلی قرار می گیرد. در چه مواردی ممکن است اینگونه نباشد؟\nالبته توجه شود، حافظه محلی (Local Memory) در CUDA بخشی از حافظه سراسری است و چون مختص هر ترد است، هم برای read و هم برای write کش می شود. در OpenCL منظور از حافظه محلی همان حافظه اشتراکی در داخل SM است که On-Chip است."
  },
  {
   "id": 228,
   "type": "message",
   "date": "2019-07-27T17:14:03",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 227,
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 702,
   "height": 179,
   "text": ""
  },
  {
   "id": 229,
   "type": "message",
   "date": "2019-07-27T17:14:35",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 707,
   "height": 82,
   "text": ""
  },
  {
   "id": 230,
   "type": "message",
   "date": "2019-07-27T17:49:11",
   "from": "Ali Riahi",
   "from_id": "user73243136",
   "reply_to_message_id": 229,
   "text": "یعنی اگر دسترسی ها فقط به یک اندیس ثابت از آرایه انجام شود، کمپایلر آرایه را تبدیل به یک متغیر معمولی می کند (بهینه سازی در سطح کمپایلر). بنابراین آرایه در رجیستر فایل تعریف نمی شود. متشکرم"
  },
  {
   "id": 231,
   "type": "message",
   "date": "2019-07-27T18:01:14",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 230,
   "text": "خواهش می کنم. ممنون از کامنت خوبتون🙏🙏👌"
  },
  {
   "id": 237,
   "type": "message",
   "date": "2019-07-29T16:14:57",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    " \n\n🔴 حافظه لوکال یا محلی\n\nحافظه محلی که LMEM نیز به آن گفته می شود به صورت فیزیکی وجود نداشته و یک مفهوم انتزاعی است. حافظه محلی  در سطح یک نخ می باشد. به عبارت دیگر حافظه محلی هر چیزی است که روی پشته بوده و نمی تواند در رجیسترها قرار بگیرد. دامنه یا حوزه مورد استفاده حافظه محلی، تنها نخ است. در حقیقت حافظه محلی در حافظه گلوبال قرار دارد. تفاوت حافظه لوكال با حافظه گلوبال در این است که آدرس دهی حافظه لوكال توسط کامپایلر حل و فصل شده و داده های ذخیره شده در حافظه L1 کش می شوند."
   ]
  },
  {
   "id": 244,
   "type": "message",
   "date": "2019-07-29T22:45:10",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "text": [
    "حوزه اموزشی گروه:\nاموزش برنامه نویسی متلب\nپردازش تصویر\nداده کاوی\n یادگیری ماشین\nپردازش سیگنال دیجیتال\nلینک گروه:\n",
    {
     "type": "link",
     "text": "https://t.me/joinchat/Bx-bmUELJ36uDGBQzkBQug"
    },
    ""
   ]
  },
  {
   "id": 253,
   "type": "message",
   "date": "2019-07-30T13:24:26",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1024,
   "height": 763,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    " \n\n📣 در دیوایس Fermi حافظه گلوبال و لوكال در حافظه L1 کش می شوند اما در دیوایس های Kepler و Maxwell فقط حافظه لوکال کش می شود. بنابراین می توان گفت که در بعضی دیوایس ها حافظه کش L1 مشابه حافظه اشتراکی بوده و دارای ظرفیتی مشابه آن (۱۶ و ۳۲ یا ۴۸ کیلوبایت) است. هر جریان چند پردازنده یا SM، حافظه کش L1 مختص خود را دارد. حافظه کش L2 تمامی دسترسی های حافظه گلوبال و لوکال را کش می کند و ظرفیت آن تقریبا 1 مگابایت است. حافظه کش L2 توسط همه جریان های چند پردازنده یا SM به اشتراک گذاشته شده است."
   ]
  },
  {
   "id": 254,
   "type": "message",
   "date": "2019-07-30T15:49:43",
   "from": "🔒Unique",
   "from_id": "user315813548",
   "text": "سلام دوستان\nمن قبلا بدون مشکل از qt استفاده میکردم ... اما الان خواستم استفاده کنم خطای عجبی میده که از صبح درگیرشم \nکتابخونه های استاندارد ++c رو الان نمیشناسه ... \n\n..\\..\\programs\\Qt\\Qt5.8.0\\5.8\\msvc2015_64\\include\\QtCore/qglobal.h(45): fatal error C1083: Cannot open include file: 'type_traits': No such file or directory\nopenssl_rsa.cpp(1): fatal error C1083: Cannot open include file: 'iostream': No such file or directory"
  },
  {
   "id": 255,
   "type": "message",
   "date": "2019-07-30T16:51:32",
   "edited": "2019-07-30T16:51:40",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "reply_to_message_id": 254,
   "text": "سلام\nباتوجه به اینکه میگید قبلا درست کار میکرده\nمیخواین یه بار پروژه رو clean بکنید و دوباره ازش build بگیرید ببینید اوکی میشه"
  },
  {
   "id": 259,
   "type": "message",
   "date": "2019-07-30T19:08:41",
   "from": "🔒Unique",
   "from_id": "user315813548",
   "reply_to_message_id": 255,
   "text": "نه نشد"
  },
  {
   "id": 260,
   "type": "message",
   "date": "2019-07-30T19:11:27",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "text": "روی پروژه راست کلیک بکنید\nqt project setting -> qt modules\nیه سریش بسته به پروژه تون باید تیک داشته باشن"
  },
  {
   "id": 261,
   "type": "message",
   "date": "2019-07-30T19:34:38",
   "from": "🔒Unique",
   "from_id": "user315813548",
   "reply_to_message_id": 260,
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 387,
   "height": 427,
   "text": ""
  },
  {
   "id": 262,
   "type": "message",
   "date": "2019-07-30T19:35:07",
   "from": "🔒Unique",
   "from_id": "user315813548",
   "text": "qt modules \nنمیبینم هیچ جا"
  },
  {
   "id": 266,
   "type": "message",
   "date": "2019-08-01T15:43:36",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "video_file",
   "mime_type": "video/mp4",
   "duration_seconds": 100,
   "width": 640,
   "height": 360,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nGauGAN, the smart paintbrush that turns rough sketches into photorealistic masterpieces, is being used by the world’s leading creators to prototype ideas & make rapid changes to synthetic scenes. Create your own masterpiece on AIPlayground: ",
    {
     "type": "link",
     "text": "https://nvda.ws/319Bd0B"
    },
    ""
   ]
  },
  {
   "id": 299,
   "type": "message",
   "date": "2019-08-02T09:53:16",
   "from": "Mostafa",
   "from_id": "user588993842",
   "forwarded_from": "CUDA",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "video_file",
   "mime_type": "video/mp4",
   "duration_seconds": 122,
   "width": 640,
   "height": 360,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nAmber, a particle simulations code based on CUDA, is ushering in a new era of  drugdiscovery and design. Hear professors David Cerutti and Taisung Lee explain how it will impact people’s lives: ",
    {
     "type": "link",
     "text": "https://nvda.ws/2LKmgyd"
    },
    ""
   ]
  },
  {
   "id": 426,
   "type": "message",
   "date": "2019-08-03T07:10:53",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    " \n\n🔴 حافظه گلوبال یا سراسری\n\nحافظه گلوبال که GMEM نیز به آن گفته می شود حافظه اصلی بر روی جی پی یو می باشد. حافظه گلوبال با گریدها تعامل دارد و برای تعامل بین گریدها از این حافظه استفاده می گردد. حافظه گلوبال با حافظه های با دسترسی تصادفی پویا یا DRAM پیاده سازی شده است. خواندن از DRAMA یک فرآیند زمان بر است. DRAM های جدید از یک پروسه موازی استفاده می کند. هر بار یک مکان مورد دسترسی قرار می گیرد، بسیاری از مکان های متوالی که شامل مکان های مورد درخواست هستند، مورد دسترسی قرار می گیرند. اگر یک برنامه قبل از رفتن به مکانهای دیگر از داده های مکان های متوالی استفاده کند، DRAMها نزدیک پیک اعلان شده پهنای باند حافظه گلوبال کار می کنند. از حافظه گلوبال غالبا به عنوان ورودی و خروجی کرنل استفاده می شود."
   ]
  },
  {
   "id": 487,
   "type": "message",
   "date": "2019-08-07T00:04:15",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    " \n\n🔴 حافظه گلوبال یا سراسری\n\nهر کرنل توسط یک گرید اجرا شده و گریدها هم فقط با حافظه گلوبال کار می کنند. برای انتقال داده ها از هاست به دیوایس همان طور که قبلا نیز گفته شد پس از رزرو و تخصیص اندازه خاصی از حافظه بر روی دیوایس، داده های ورودی به دیوایس به منظور پردازش داده ها منتقل می شوند و پس از انجام عملیات پردازش بر روی داده ها،داده های پردازش شده به هاست منتقل می شوند که برای این عملیات از حافظه گلوبال استفاده می شود.\n برای انتقال داده های بین هاست و دیوایس از گذرگاه PCI استفاده می گردد که سرعت انتقال داده ها در یک PCIe x16 Gen2 از هاست به دیوایس (cudaMemcpyHostToDevice) برابر با 8 گیگابایت بر ثانیه بوده درصورتی که سرعت انتقال داده ها از دیوایس به هاست (cudaMemcpyDeviceToHost) حداقل بالای 140 گیگابایت بر ثانیه است.\n بنابراین باید محاسباتی را با جی پی یو انجام دهید که تا حد امکان از I / O کمتری برخوردار باشد. ارسال داده ها بین هاست و دیوایس دارای سرعت پایینی بوده و هر چه برنامه شما هم توسط كودا سریع اجرا شود اما ورودی و خروجی زیادی داشته باشد مقرون به صرفه نمی باشد. حافظه گلوبال دارای دامنه یا حوزه مورد استفاده به صورت سراسری و لایف تایمی از زمان تخصیص حافظه تا زمان آزادسازی آن حافظه در برنامه می باشد به عبارت دیگر تا قبل از دستور cudaFree ."
   ]
  },
  {
   "id": 488,
   "type": "message",
   "date": "2019-08-07T01:44:30",
   "from": "Ghzsal",
   "from_id": "user344760551",
   "reply_to_message_id": 487,
   "text": "🙏🙏🙏🙏🙏🙏🙏🙏"
  },
  {
   "id": 501,
   "type": "message",
   "date": "2019-08-10T19:47:02",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#اطلاعات_عمومی"
    },
    "\n\n🔔 کودا شامل نسل های مختلفی با قابلیت های محاسباتی متفاوتی است. کارت گرافیک های سری G80 با نخستین نسخه CUDA ارائه شدند. از طرفی قابلیت محاسباتی در سخت افزار تثبیت شده است. با در نظر گرفتن اینکه NVIDIA حداقل هر دو سال پلتفرم جدیدی را ارائه می دهد، در سال های کوتاهی که CUDA ارائه شده است تا به امروز افزایش زیادی در قدرت محاسباتی مشاهده شده است. فهرست کاملی از تفاوت های بین نسل های محاسباتی در راهنمای برنامه نویسی NVIDIA CUDA، می توان یافت که به عنوان بخشی از CUDA SDK ارائه شده است."
   ]
  },
  {
   "id": 502,
   "type": "message",
   "date": "2019-08-10T19:47:02",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#اطلاعات_عمومی"
    },
    "\n\n🔔 قابلیت محاسباتی  1.0\n\nدر کارت های قدیمی تر یافت می شود، مثل Ultra  8800  و بسیاری از کارت های سری 8000 و همین طورTesla C/D/ S870 . اصلی ترین ویژگی که کارت های با قابلیت محاسباتی 1.0 فاقد آن هستند عمليات تجزیه ناپذیر هستند. عملیات تجزیه ناپذیر به آن دسته از عملیاتی گفته می شود که می توان تضمین کرد به صورت کامل و بدون ایجاد وقفه توسط نخ های دیگر اجرا شود. در واقع سخت افزار، یک نقطه ی مانع را در ورودی تابع تجزیه ناپذیر پیاده سازی می کند و تکمیل عملیات ( add , sub ، min ، max و عملگرهای منطقی or  , xor و غیره) را به صورت یک عمل تضمین می کند. یکی از تغییرات اساسی که در دستگاه های با قابلیت محاسباتی 1.1 به وجود آمد، پشتیبانی از انتقال داده ها و اجرای کرنل همپوشان، در اکثر دستگاه ها و نه همه ی آنها بود. این SDK، تابع ()cudaGetDeviceProperties را به منظور برگرداندن ویژگی deviceOverlap، فراخوانی می کند، که در صورت موجود بودن این عملکرد تعریف می شود."
   ]
  },
  {
   "id": 511,
   "type": "message",
   "date": "2019-08-12T03:49:03",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "reply_to_message_id": 502,
   "text": "👍"
  },
  {
   "id": 550,
   "type": "message",
   "date": "2019-08-16T15:39:21",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#اطلاعات_عمومی"
    },
    "\n\n🔔 قابلیت محاسباتی 2.0 \n\n دستگاههای با قابلیت محاسباتی 2.0 به معماری Femi تغيير وضعیت دادند. برخی از مهم ترین تغییرات سخت افزار با قابلیت محاسباتی 2 عبارت اند از: \n\n1️⃣ معرفی حافظه نهان L1 از ۱۶ کیلو بایت به ۴۸ کیلوبایت در هر SP. \n\n2️⃣ معرفی یک حافظه نهان L2 اشتراکی برای تمام SMها .\n\n3️⃣  پشتیبانی از بررسی حافظه مبتنی بر کد اصلاح خطا (ECc) و اصلاح خطا در دستگاه های  Tesla.\n\n4️⃣ پشتیبانی از موتورهای کپی مضاعف در دستگاه های Tesla .\n\n5️⃣  توسعه ی اندازه ی حافظه اشتراکی از ۱۶ کیلوبایت تا حداکثر ۲۸ کیلوبایت در هر SM .\n\n6️⃣هم ترازی ۱۲۸ بیتی برای ادغام بهینه ی داده ها.\n\n7️⃣ افزایش تعداد بانک های حافظه اشتراکی از ۱۶ به ۳۲ عدد.\n\nحافظه نهان L1 (سطح یک ) حافظه نهانی است که بر روی دستگاه وجود دارد و سریع ترین حافظه نهان موجود است . معرفی یک حافظه نهان، کار را برای بسیاری از برنامه نویسان، به منظور نوشتن برنامه ای با عملکرد خوب بر روی سخت افزار GPU، بسیار آسان تر می کند، همچنین به برنامه های کاربردی این اجازه را میدهد که از الگوی حافظه ی مشخصی در زمان کامپایل پیروی نکنند. با این حال، برنامه ی کاربردی برای به کارگیری حافظه نهان یا باید یک الگوی حافظه ترتیبی داشته باشد و یا حداقل از استفاده ی مجدد داده ها بهره گیرد.  در Fermi، حافظه نهان L2 حداکثر ۷۶۸ کیلوبایت است و آنچه که مهم است این است که حافظه نهان يکپارچه است به این معنی که اشتراکی است و نمای ثابتی را برای SM فراهم می کند. این امر اجازه ی ارتباط بين بلاکی بسیار سریع تری را از طریق عمليات تجزیه ناپذیر سراسری می دهد. استفاده از حافظه نهان اشتراکی در مقایسه با حافظه سراسری در GPU امکان اجرای بسیار سریع تری را فراهم می کند."
   ]
  },
  {
   "id": 551,
   "type": "message",
   "date": "2019-08-16T16:04:48",
   "from": "Ghzsal",
   "from_id": "user344760551",
   "reply_to_message_id": 550,
   "text": "🙏🙏🙏🙏🙏🙏"
  },
  {
   "id": 571,
   "type": "message",
   "date": "2019-08-18T10:50:40",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 815,
   "height": 522,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nAccelerate genome assembly and analysis with the upgraded Clara Genomics SDK 0.2. Learn all the new features: ",
    {
     "type": "link",
     "text": "https://nvda.ws/2OWejIC"
    }
   ]
  },
  {
   "id": 574,
   "type": "message",
   "date": "2019-08-18T17:24:40",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "video_file",
   "mime_type": "video/mp4",
   "duration_seconds": 29,
   "width": 640,
   "height": 360,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nWith recent breakthroughs in NLP, the world is one step closer to conversational AI. Learn how we’re leading a new era of customer engagement in every industry. ",
    {
     "type": "link",
     "text": "https://nvda.ws/2ORNDIZ"
    },
    ""
   ]
  },
  {
   "id": 598,
   "type": "message",
   "date": "2019-08-19T18:03:10",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "video_file",
   "mime_type": "video/mp4",
   "duration_seconds": 22,
   "width": 1280,
   "height": 720,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nBy training neural networks using actual human voices, DeepZen is transforming text-to-speech processing. Learn how they are leveraging NGC AI containers to create human-like speech: ",
    {
     "type": "link",
     "text": "https://nvda.ws/2Z4vSWV"
    }
   ]
  },
  {
   "id": 751,
   "type": "message",
   "date": "2019-08-26T14:26:42",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n✅حافظه اشتراکی\n\nیکی از امکانات معماری جی پی یو، وجود حافظه اشتراکی در هر بلاک است که به آن Shared Memory گفته می شود، این حافظه به صورت on - chip بوده و دارای سرعت بالایی است، اما اندازه کوچکی دارد. از این حافظه بیشتر برای برقراری ارتباط نخ های داخل یک بلاک باهم و یا ذخیره و یا لود کردن مجدد داده ها در طول اجرای یک برنامه که نخ دائما به آن نیاز دارد استفاده می شود.  اگر حافظه اشتراکی وجود نداشته باشد، نخها مجبورند برای برقراری ارتباط باهم و یا ذخیره یا لود کردن داده های جاری موردنیازشان دائم به حافظه گلوبال رجوع کنند. استفاده در ست از حافظه های گلوبال و اشتراکی می تواند کارایی برنامه  را تا دهها برابر افزایش دهد.  البته باید توجه کرد که فضاهای حافظه گلوبال و اشتراکی کش نمی شوند. میزان حافظه اشتراکی را به صورت زمان اجرا و از طریق هاست و در قسمت فراخوانی کرنل ( البته این برای زمانی است که از نوع حافظه اشتراکی داینامیک استفاده شود ) می توان مشخص کرد."
   ]
  },
  {
   "id": 752,
   "type": "message",
   "date": "2019-08-26T14:26:42",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n✅ استفاده از حافظه اشتراکی\n\nدر کودا  برای استفاده از حافظه اشتراکی در کرنل از توصیف کننده یا تعیین اعلان متغیر _shared_قبل از داده موردنظر استفاده می کنیم. \n\n 🖍 حافظه اشتراکی ایستا یا استاتیک \nاگر اندازه آرایه حافله اشتراکی در زمان کامپایل را بدانیم در این صورت ما می توانیم به صراحتا یک آرایه تعریف کنیم . \n_shared_int s[ 64]\n\n🖌 حافظه اشتراکی پویا یا داینامیک\nاگر اندازه آرایه حافظه اشتراکی را از قبل ندانیم، در این حالت، تخصیص اندازه حافظه اشتراکی در هر بلاک باید به بایت و توسط پارامتر سوم پیکربندی اجرای کرنل صورت می گیرد که پارامتری اختیاری در اجرای کرنل است.\ndynamicReverse << <1, n, n*sizeof(int) >> >();"
   ]
  },
  {
   "id": 753,
   "type": "message",
   "date": "2019-08-26T14:34:08",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#اطلاعات_عمومی"
    },
    " \n\n🔗 قابلیت محاسباتی .۳ \n\nمعماری Kepler در سال ۲۰۱۰ بر اساس معماری Fermi ساخته شد. Kepler اولین ریز معماری NVIDIA است که بر روی مصرف بهینه ی انرژی تمرکز کرده است. در حالی که هدف معماری قبلی NVIDIA، افزایش کارایی محاسباتی بود، در معماری Kepler ، NVIDIA بر روی بهره وری، قابلیت برنامه ریزی و کارایی متمرکز شد.   هدف کارایی از طریق منابع اجرایی بیشتر (هسته های CUDA، رجیستر و حافظه نهان بیشتر) و قابلیت Kepler در رسیدن به سرعت پالس ساعت حافظه شش گیگاهرتز، کارایی Kepler را در مقایسه با GPU های قبلی افزایش داده است.\n\n🔗 قابلیت محاسباتی .5 \n\nمعماری GPU با قابلیت محاسباتی  5 با نام Maxwell معرفی شده است. این معماری در مدل های نهایی مجموعه 700 GeForce و همچنین در مجموعه GeForce 900 , GeForce 800M و Quadro Mxxx مورد استفاده قرار گرفت. اولین نسل از محصولات Maxwell (با کد تراشه GM107GMT08) که در بازار عرضه شدند عبارت اند از، 745 GTX 750 7750 Ti ,GeForce GTX و GTX850M860M GeForce 830M/840M  این  تراشه های جدید ویژگی های جدیدی را برای کاهش مصرف انرژی ارائه کردند. برخی از مهم ترین تغییرات در \nسخت افزار با قابلیت محاسباتی  عبارت اند از: \n\n☑️ دارای SM با کارایی بسیار بالا و بهبود مصرف انرژی \n\n☑️ تخصيص ۶۴ کیلوبایت حافظه اشتراکی به ازای هر SM برخلاف معماری های Femmi و Kepler که ۶۴ کیلوبایت حافظه را بین حافظه نهان L1 و حافظه اشتراکی تقسیم می کردند. \n\n☑️ افزایش تعداد بلاک های نخ به ازای هر SM از ۱۶ عدد در Kepler به ۳۲ عدد در Maxwell"
   ]
  },
  {
   "id": 758,
   "type": "message",
   "date": "2019-08-26T14:46:53",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 682,
   "height": 341,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nTo help improve diagnostic & treatment accuracy for prostate cancer patients, NVIDIA scientists partnered with NIH to develop a new segmentation model based on a domain generalization method through Clara Train SDK (available on NGC today).\n",
    {
     "type": "link",
     "text": "https://news.developer.nvidia.com/nvidia-and-nih-researchers-developed-an-ai-tool-with-clara-train-sdk-to-better-detect-prostate-cancer/"
    }
   ]
  },
  {
   "id": 860,
   "type": "message",
   "date": "2019-08-29T16:09:22",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#اطلاعات_عمومی"
    },
    "\n\n📣 قابلیت محاسباتی  ۶\n\n معماری GPU با قابلیت محاسباتی ۶ با نام Pascal معرفی شده است.\n این معماری در ماه آوریل سال ۲۰۱۶ با تراشه GP100 معرفی شد. برخی از مهم ترین تغییرات در سخت افزار با قابلیت محاسباتی ۶ عبارت اند از:\n\n1️⃣ در Pascal هر SM شامل ۶۴ هسته ی CUDA است. Maxwell شامل ۱۲۸، Kepler شامل ۱۹۲، Fermi شامل ۳۲ و Tesla شامل تنها هشت هسته ی CUDA در یک SM هستند. SM متعلق به GP100 به دو بلاک پردازشی تقسیم شده است که هر کدام شامل ۳۲ هسته ی CUDA با دقت منفرد، یک بافر دستورالعمل، یک زمان بند تار، دو واحد نگاشت بافت و دو واحد توزیع کننده است. \n\n2️⃣  پشتیبانی از CUDA با قابلیت محاسباتی  ۶ . \n\n3️⃣ حافظه با پهنای باند بسیار بالا ۲(HBM2)- برخی از کارت ها، ۱۶ گیگابایت HBM2 را در چهار دسته با گذرگاه ۴۰۹۶ بیتی با پهنای باند حافظه ۷۲۰ گیگابایت بر ثانیه ارائه می دهند. \n\n4️⃣ حافظه یکپارچه - معماری حافظه ای که در آن CPU و GPU با کمک تکنولوژی به نام  موتور مهاجرت صفحه می توانند به هر دو سیستم حافظه اصلی و حافظه بر روی کارت گرافیک دسترسی داشته باشند. \n\n5️⃣ وجود NVLink- گذرگاهی با پهنای باند بالا بین CPU و GPU و بین چند GPU. این گذرگاه سرعت انتقال بسیار بالاتری را نسبت به PCI Express ارائه میدهد و بین ۸۰ تا ۲۰۰ گیگابایت بر ثانیه برآورد شده است.\n\n6️⃣ دو برابر شدن تعداد رجیسترها به ازای هر هسته ی CUDA در مقایسه \nبا Maxwell \n\n7️⃣  سیستم زمانبندی تنظیم بار پویا. این ویژگی به زمان بند اجازه میدهد که به صورت پویا میزان تخصیص GPU  به چندین وظیفه را تنظیم کند."
   ]
  },
  {
   "id": 919,
   "type": "message",
   "date": "2019-08-31T14:54:02",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "forwarded_from": "CUDA",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "video_file",
   "mime_type": "video/mp4",
   "duration_seconds": 21,
   "width": 1280,
   "height": 720,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nWatch NVIDIA's David Nola explain how NVIDIA Clara Toolkits make building AI easy by providing tools that make data annotation, training and deployment seamless for medical imaging applications."
   ]
  },
  {
   "id": 1108,
   "type": "message",
   "date": "2019-09-07T16:41:01",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 367,
   "height": 140,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🖌 دسترسی و بازیابی از حافظه ها \n\n🔗حافظه پیوسته\n\nاستفاده از حافظه پیوسته یا به عبارت دیگر نوشتن برنامه کودا به گونه ای که در آن پیوستگی حافظه در دسترسی ها به حافظه رعایت شود موجب افزایش سرعت اجرای برنامه و کاهش زمان اجرای آن می گردد. همانطور که در شکل نشان داده شده است محتوای آدرس های حافظه یا به عبارت دیگر داده ها و مقادیر داخل خانه ها یا سلول های حافظه به صورت پیوسته و متصل به هم یا اصطلاحا contiguous قرار دارد که مثلا برای خواندن مقادیر از چهار سلول حافظه از یک چانک یا تکه استفاده می شود و این حالت بسیار عالی است."
   ]
  },
  {
   "id": 1123,
   "type": "message",
   "date": "2019-09-07T22:50:36",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 367,
   "height": 140,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🖌 دسترسی و بازیابی از حافظه ها \n\n🔘 دسترسی نوع Strided\n\nدر دسترسی نوع Strided یا اصطلاحا گام محتوای سلول های حافظه به صورت یک در میان و با طول گام یا اصطلاحا strided قرار دارد که برای خواندن همان چهار مقادیر از چهار سلول حافظه از دو چانک استفاده می شود و این حالت نسبت به حالت coalesced مناسب نیست."
   ]
  },
  {
   "id": 1238,
   "type": "message",
   "date": "2019-09-12T11:54:41",
   "from": "Reza Behboodi",
   "from_id": "user219101078",
   "forwarded_from": "CUDA",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "video_file",
   "mime_type": "video/mp4",
   "duration_seconds": 134,
   "width": 640,
   "height": 360,
   "text": "CUDA is making it possible for developers to visualize and simulate high-resolution molecular dynamics using  NAMD and  VMD. Hear more from John Stone, Senior Research Programmer at BeckmanInst."
  },
  {
   "id": 1311,
   "type": "message",
   "date": "2019-09-14T19:53:22",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🖌 دسترسی و بازیابی از حافظه ها \n\n🔘 دسترسی  random \n\nدر این نوع دسترسی ها محتوای سلول های حافظه به صورت تصادفی یا اصطلاحا random قرار دارد که برای خواندن همان چهار مقادیر از چهار سلول حافظه نیاز به چانک های متعددی داریم که از این جهت، این حالت بدترین حالت ممکن می باشد. با توجه به مطالب ذکر شده پی به ارزشمند بودن حافظه coalesced  می بریم و باید سعی کنیم در برنامه ها آن را لحاظ کنیم.  دسترسی به حافظه پیوسته یا پیوستگی حافظه اشاره به ترکیب دسترسی های متعدد حافظه به درون یک تراکنش دارد. در جی پی یوهای Tesla K20 هر 128 بایت متوالی حافظه (32 کلمه با دقت معمولی ) می تواند توسط یک ریسمان  (32 نخ متوالی) در یک تراکنش تکی، مورد دسترسی قرار گیرد."
   ]
  },
  {
   "id": 1312,
   "type": "message",
   "date": "2019-09-14T19:53:27",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "video_file",
   "mime_type": "video/mp4",
   "duration_seconds": 97,
   "width": 854,
   "height": 480,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nDeepZen is changing the way text-to-speech systems process language using GPU-accelerated containers from NGC:\n",
    {
     "type": "bold",
     "text": "DeepZen Creating Human-Like Speech with NGC Containers"
    }
   ]
  },
  {
   "id": 1361,
   "type": "message",
   "date": "2019-09-16T12:52:24",
   "from": "Hr Mahjoobin",
   "from_id": "user86002292",
   "text": "سلام.کسی برنامه نویسی cudaدرmatlabکار کرده؟"
  },
  {
   "id": 1362,
   "type": "message",
   "date": "2019-09-16T12:52:24",
   "from": "Hr Mahjoobin",
   "from_id": "user86002292",
   "text": "🙏🙏🙏"
  },
  {
   "id": 1363,
   "type": "message",
   "date": "2019-09-16T13:41:50",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "reply_to_message_id": 1361,
   "text": "سلام سوالتون چیه؟"
  },
  {
   "id": 1372,
   "type": "message",
   "date": "2019-09-16T16:19:20",
   "from": "Hr Mahjoobin",
   "from_id": "user86002292",
   "reply_to_message_id": 1363,
   "text": "سلام. من cuda روی متلب نصب کردم. ولی برای برنامه نویسی cuda در متلب غیر چند دستور، چیزی دیگه پیدا نکردم، ونمتونم برنامه نویسی cuda انجام بدم. باید چی کار کنم.؟"
  },
  {
   "id": 1373,
   "type": "message",
   "date": "2019-09-16T16:46:35",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 1372,
   "text": "سلام، به هر حال شما باید مفاهیم اولیه رو بدونید. که تو همین گروه یا داکیومنتهای خود nvidia هست. بعد میتونید از ویدیوهای یوتیوب استفاده کنید."
  },
  {
   "id": 1618,
   "type": "message",
   "date": "2019-09-27T21:02:47",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🖍 حافظه پین شده\n\n استفاده از حافظه پین شده و انجام انتقال های داده به وسیله آن به دستیابی به بالاترین میزان پهنای باند بین هاست و دیوایس می انجامد.\n\n🔔 یادآوری ( حافظه مجازی و Page File ) \n\nحافظه مجازی یا Virtual Memory زمانی استفاده می شود که سیستم عامل حافظه RAM کافی برای اجرای برنامه ها را در اختیار نداشته باشد. حافظه مجازی در واقع استفاده از فضای هارد دیسک موجود روی سیستم به عنوان RAM می باشد. زمانی که یک کامپیوتر برای اجرای برنامه ها فضای RAM مورد نیاز را نداشته باشد، سیستم عامل داده های موجود در داخل RAM را به داخل حافظه مجازی یا Virtual Memory که آن را به عنوان Page File در ویندوز می شناسند منتقل می کند و برای نگهداری این Page File قطعا یک قسمت از هارد دیسک استفاده می شود. دقت کنید که همان در سیستم عامل لینوکس به عنوان حافظه SWAP شناخته می شود، حافظه مجازی می تواند بلوک کامل از داده ها را همزمان با اجرا شدن در حافظه RAM در خود نگهداری کند. بنابراین حافظه مجازی این قابلیت را به سیستم عامل میدهد که چندین برنامه را در یک زمان استفاده کند و در اصطلاح قابلیت های چندبرنامگی یا Multiprogramming سیستم را افزایش می دهد."
   ]
  },
  {
   "id": 1619,
   "type": "message",
   "date": "2019-09-27T21:03:01",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 585,
   "height": 307,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    " \n\n🖍  هنگام اختصاص حافظه هاست که برای انتقال اطلاعات به جی پی یو استفاده می شود دو نوع حافظه برای انتخاب وجود دارد: حافظه پین شده و پین نشده. در حافظه پین نشده swap بین حافظه رم و هارد صورت گرفته و از page file استفاده می گردد که باعث کاهش کارایی و سرعت برنامه می گردد. داده های هاست در حالت پیش فرض به صورت pageable است از این رو دیوایس نمی تواند دسترسی مستقیم به حافظه pageable هاست داشته باشد بنابراین زمانی که یک داده انتقالی از هاست با حافظه pageable به حافظه دیوایس فراخوانی می شود، درایور کودا در ابتدا باید یک page - locked یا اصطلاحا pinned تخصیص دهد سپس آرایه هاست، داده مربوط به هاست را به آرایه پین شده کپی می کند و سپس داده از آرایه پین شده به حافظه دیوایس همانطور که در شکل نشان داد شده  منتقل می شود. تخصيص حافظه هاست پین شده در کودا سیاسی پلاس پلاس با استفاده از دستور ()cudaHostAlloc و آزادسازی آن توسط دستور ()cudaFreeHost صورت می گیرد."
   ]
  },
  {
   "id": 1822,
   "type": "message",
   "date": "2019-10-11T12:02:43",
   "from": "Ghzsal",
   "from_id": "user344760551",
   "reply_to_message_id": 1619,
   "text": "🙏🙏🙏🙏🙏🙏"
  },
  {
   "id": 1839,
   "type": "message",
   "date": "2019-10-12T21:27:04",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 651,
   "height": 492,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nIf you use the NVIDIA Visual Profiler or the nvprof command line tool, it’s time to transition to something newer: NVIDIA Nsight Tools. \n\n",
    {
     "type": "link",
     "text": "https://devblogs.nvidia.com/transitioning-nsight-systems-nvidia-visual-profiler-nvprof/"
    },
    ""
   ]
  },
  {
   "id": 1852,
   "type": "message",
   "date": "2019-10-13T16:21:28",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 880,
   "height": 660,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🖍  حافظه یکپارچه\n\nحافظه یکپارچه، یک فضای آدرس حافظه مجزا است که از هر پردازنده در یک سیستم در دسترس است. این تکنولوژی سخت افزاری/نرم افزاری اجازه می دهد تا برنامه های کاربردی داده هایی از کد در حال اجرا را تخصیص بدهند که بتوانند بر روی هر سی پی یو یا جی پی یویی خوانده یا نوشته  شوند. تخصيص حافظه یکپارچه با استفاده از ()cudaMallocManaged صورت می گیرد. یک تابع تخصیص که یک اشاره گر (ptr در قطعه کد زیر) را برمیگرداند که از هر پردازنده ای قابل دستیابی است.\n",
    {
     "type": "bold",
     "text": "cudaError_t  cudaMallocManaged ( void ptr , size_t size); \n"
    },
    "زمانی که کد بر روی یک سی پی یو یا جی پی یو اجرا می شود، دسترسی به داده تخصیص یافته با این روش  امکان پذیر است. سیستم نرم افزاری و سخت افزاری مربوط به کودا از مهاجرت صفحات حافظه به حافظه پردازنده دسترسی جلوگیری می کند. نکته کلیدی در اینجا این است که معماری جی پی یوی پاسکال اولین جی پی یوی با پشتیبانی سخت افزاری برای خطایابی صفحه حافظه مجازی و مهاجرت از طریق موتور مهاجرت صفحه خودش است. همچنین GPU  های قدیمی تر بر مبنای معماری های Kepler و  Maxwell به صورت محدودتری از حافظه یکپارچه پشتیبانی می کنند."
   ]
  },
  {
   "id": 1853,
   "type": "message",
   "date": "2019-10-13T17:25:40",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1024,
   "height": 512,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nNatural language processing is a critical part of building better chat bots and AI assistants. Join 10/17 webinar to learn how to unlock the potential of conversational AI in financial services.\n\n",
    {
     "type": "link",
     "text": "nvda.ws/2mwdN6e"
    }
   ]
  },
  {
   "id": 1868,
   "type": "message",
   "date": "2019-10-14T14:53:19",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1024,
   "height": 510,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nLearn how to use Nsight Compute to inspect your kernels in this new blog from NVIDIA's engineering team.\n\n",
    {
     "type": "link",
     "text": "https://devblogs.nvidia.com/using-nsight-compute-to-inspect-your-kernels/"
    }
   ]
  },
  {
   "id": 2117,
   "type": "message",
   "date": "2019-10-29T21:35:10",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 833,
   "height": 429,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nthe best paper award and a NVIDIA TITAN V at the first international workshop on Domain Adaptation and Representation Transfer 2019! Read their paper on \"Noise as Domain Shift: Denoising Medical Images by Unpaired Image Translation\"\n",
    {
     "type": "link",
     "text": "https://arxiv.org/abs/1910.02702"
    }
   ]
  },
  {
   "id": 2140,
   "type": "message",
   "date": "2019-10-30T18:52:27",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1200,
   "height": 219,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nnew work on memory uses a neural network's weights as fast and compressive associative storage. Reading from the memory is performed by approximate minimisation of the energy modelled by the network. ",
    {
     "type": "link",
     "text": "https://arxiv.org/abs/1910.02720"
    }
   ]
  },
  {
   "id": 2235,
   "type": "message",
   "date": "2019-11-04T09:01:15",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 800,
   "height": 800,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nThe GPU Operator is designed to simplify  GPU management in Kubernetes, making large-scale hybrid-cloud and edge operations possible and efficient."
   ]
  },
  {
   "id": 2265,
   "type": "service",
   "date": "2019-11-05T20:43:06",
   "actor": "Moein",
   "actor_id": "user751442599",
   "action": "join_group_by_link",
   "inviter": "Group",
   "text": ""
  },
  {
   "id": 2267,
   "type": "message",
   "date": "2019-11-05T20:45:17",
   "from": "Moein",
   "from_id": "user751442599",
   "text": "سلام، یک رشته را داریم که از حروف  ها و اعداد تشکیل شده است ،تابعی رو میخام که یک کاراکتر را به عنوان ورودی بگیرد و تشخیص دهد که عدد هست یانه؟ ممنون"
  },
  {
   "id": 2268,
   "type": "message",
   "date": "2019-11-05T20:53:08",
   "from": "Aidin Noori",
   "from_id": "user57661101",
   "reply_to_message_id": 2267,
   "text": "سلام، اینکه یه تابعی باشه یک کاراکتر از ورودی بگیره و تشخیص بده که عدده یا نه ربطش با اون رشته که می‌فرمایین از اعداد و حروف تشکیل شده چیه؟"
  },
  {
   "id": 2269,
   "type": "message",
   "date": "2019-11-05T20:54:27",
   "from": "Moein",
   "from_id": "user751442599",
   "reply_to_message_id": 2268,
   "text": "میخام هر بار یک کاراکتر از رشته رو به تابع بدم و تعداد دفعاتی که عدد داخل رشته هستش رو محاسبه کنم"
  },
  {
   "id": 2270,
   "type": "message",
   "date": "2019-11-05T22:24:30",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 2269,
   "text": "سلام دوست عزیز گوگل کنی لینک اول میاد."
  },
  {
   "id": 2358,
   "type": "message",
   "date": "2019-11-10T10:38:20",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🔴 مقابله با شرایط مسابقه\n\n✔️    یکی از روش های مقابله با شرایط مسابقه استفاده از دستور ()Syncthreads می باشد.  روش دیگر به کار بردن دستورات اتمیک است. هر عمل اتمیک در واقع، قادر به خواندن، تغییر و بازنویسی در حافظه، بدون تداخل با دیگر نخ ها است که عدم رخ دادن شرایط  مسابقه را تضمین می کند. روش استفاده از دستور ()syncthreads_ پاسخگوی تمام حالت ها نیست از جمله اینکه این روش برای حافظه اشتراکی به کار رفته و برای همگام سازی نخ ها در داخل بلاک ها از آن استفاده می شود، این در حالی است که روش عملیات اتمیک معمولا برای هر دو حالت حافظه اشتراکی و گلوبال به کار می رود. عملیات اتمیک در حافظه اشتراکی معمولا به منظور جلوگیری از شرایط مسابقه بین نخ های مختلف داخل بلاک های یکسان استفاده می شود و عملیات اتمیک در حافظه گلوبال برای جلوگیری از شرایط مسابقه بین دو نخ مختلف بدون در نظر گرفتن اینکه در کدام بلاک هستند استفاده می شوند."
   ]
  },
  {
   "id": 2359,
   "type": "message",
   "date": "2019-11-10T12:08:59",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🔴 نکات مربوط به عملیات اتمیک \n\n☑️  حافظه اشتراکی بسیار سریع تر از حافظه گلوبال است، بنابراین عملیات اتمیک در حافظه اشتراکی سرعت تکمیل بیشتری نسبت عملیات اتمیک در حافظه گلوبال دارد. در حالی که عملیات اتمیک، در برخی الگوریتم ها ضروری هستند، اما به حداقل رساندن استفاده از آنها تا حد امکان، به ویژه در دسترسی های مربوط به حافظه گلوبال، مهم است. همانطور که می دانید اگر دو نخ یک عملیات اتمیک را در آدرس حافظه یکسان و به صورت همزمان انجام دهند، عملیات آنها سریال می شود. بنابراین هر زمان که قصد استفاده از عملیات اتمیک را دارید، مطمئن شوید که نیازی به عملیات ترتیبی بیش از حد نباشد. اگرچه زمانی که عملیات اتمیک به درستی به کار گرفته شوند، بسیار مفید خواهند بود. توابعی مانند AtomicAdd،AtomicMin و AtomicAnd  برخی توابع مربوط به انجام عملیات صحیح اتمیک در حافظه گلوبال هستند. به عنوان مثال، ()AtomicAdd یک کلمه 32 بیتی یا 64 بیتی را از حافظه گلوبال یا اشتراکی خوانده، یک عدد صحیح را با آن جمع می کند و حاصل را دوباره در همان آدرس ذخیره می کند، تمام این عملیات نیز به صورت اتمیک صورت می پذیرد. به این معنا که هیچ نخ دیگری هنگام انجام این کار نمی تواند به این آدرس دسترسی داشته باشد.\nبرای انجام عملیات جمع اتمیک که در مثال بالا گفته شد از تابع atomicAdd به صورت زیر استفاده می کنیم.\n1. int atomicAdd( int* address, int val);\n\nتابع ()Atomic Add، همچنین می تواند داخل یک کرنل فراخوانی شود. در واقع زمانی که یک نخ این عملیات را انجام می دهد، یک آدرس حافظه خوانده شده و مقدار محتوای آن با val جمع گشته و در نهایت نتیجه حاصل در همان آدرس بازنویسی می شود."
   ]
  },
  {
   "id": 2360,
   "type": "message",
   "date": "2019-11-10T12:23:35",
   "from": "Ghzsal",
   "from_id": "user344760551",
   "reply_to_message_id": 2359,
   "text": "ممنون مهندس"
  },
  {
   "id": 2361,
   "type": "message",
   "date": "2019-11-10T12:24:48",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "text": "خواهش میکنم"
  },
  {
   "id": 2362,
   "type": "message",
   "date": "2019-11-10T15:54:16",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "reply_to_message_id": 2359,
   "text": "ممنون مهندس خیلی مفید بود"
  },
  {
   "id": 2395,
   "type": "message",
   "date": "2019-11-11T12:18:27",
   "from": "Moein",
   "from_id": "user751442599",
   "text": "سلام دوستان کسی کودا رو با زبان پایتون کار کرده؟"
  },
  {
   "id": 2425,
   "type": "message",
   "date": "2019-11-12T17:45:38",
   "from": "یاری",
   "from_id": "user174088387",
   "text": "سلام دوست عزیز سوالتون چیه؟"
  },
  {
   "id": 2452,
   "type": "message",
   "date": "2019-11-13T14:30:31",
   "from": "Moein",
   "from_id": "user751442599",
   "reply_to_message_id": 2425,
   "text": "ببخشید من google colab کار میکنم هر دفعه میخام از کارت گرافیکش استفاده کنم حدود 70 مگ حافظه کارت گرافیک رو استفاده میکنم بعدش دیگه خطای حافظه میده در حالی که حدود 16 گیگ بهم حافظه میده هر بار؟"
  },
  {
   "id": 2453,
   "type": "message",
   "date": "2019-11-13T14:31:18",
   "from": "Moein",
   "from_id": "user751442599",
   "text": "حدود یک درصدش رو استفاده میکنم دیگه اجازه دسترسی ندارم"
  },
  {
   "id": 2454,
   "type": "message",
   "date": "2019-11-13T14:34:42",
   "from": "Moein",
   "from_id": "user751442599",
   "text": "LogicError: cuMemcpyDtoH failed: an illegal memory access was encountered"
  },
  {
   "id": 2455,
   "type": "message",
   "date": "2019-11-13T14:34:56",
   "from": "Moein",
   "from_id": "user751442599",
   "text": "این  خطا رو میده"
  },
  {
   "id": 2456,
   "type": "message",
   "date": "2019-11-13T14:39:09",
   "edited": "2019-11-13T14:39:29",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "text": "اگه ممکن بخشی از کد رو هم بفرستید"
  },
  {
   "id": 2457,
   "type": "message",
   "date": "2019-11-13T14:40:22",
   "from": "Moein",
   "from_id": "user751442599",
   "text": [
    "import pycuda.gpuarray as gpuarray\nimport  numpy\na = gpuarray.arange(400, dtype=numpy.float32)\nb = gpuarray.arange(400, dtype=numpy.float32)\n",
    {
     "type": "hashtag",
     "text": "#call"
    },
    " Cuda function pass 'a' and 'b' \nresulta = a.get()\nresultb = b.get()\nprint(resulta,resultb)"
   ]
  },
  {
   "id": 2458,
   "type": "message",
   "date": "2019-11-13T14:41:01",
   "from": "Moein",
   "from_id": "user751442599",
   "reply_to_message_id": 2456,
   "text": "کدهام همون اول که میخام حافظه تخصیص بدم  اجازه تخصیص نمیده"
  },
  {
   "id": 2459,
   "type": "message",
   "date": "2019-11-13T14:43:30",
   "from": "Moein",
   "from_id": "user751442599",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1129,
   "height": 372,
   "text": ""
  },
  {
   "id": 2461,
   "type": "message",
   "date": "2019-11-13T16:04:02",
   "from": "یاری",
   "from_id": "user174088387",
   "reply_to_message_id": 2459,
   "text": "به نظر مشکل میتونه از کتابخونه pycuda،\nو یا نصب اشتباه اون در colab باشه،\n\nمی تونید به جاش از numpy استفاده کنید."
  },
  {
   "id": 2462,
   "type": "message",
   "date": "2019-11-13T16:04:18",
   "from": "یاری",
   "from_id": "user174088387",
   "text": [
    "import numpy\nfrom numba import cuda\n\n@cuda.jit\ndef kernel(a,b):\n    tidx = cuda.threadIdx.x\n    bidx = cuda.blockIdx.x\n    bdx = cuda.blockDim.x\n    pos = tidx + bidx * bdx\n    a[pos]*=2;\n    b[pos]*=5;\n\n\n\nthreadsPerBlock = 32 \nblocksPerGrid = (400 + (threadsPerBlock - 1)) // threadsPerBlock\na = numpy.arange(400, dtype=numpy.float32)\nb = numpy.arange(400, dtype=numpy.float32)\n",
    {
     "type": "hashtag",
     "text": "#call"
    },
    " Cuda function pass 'a' and 'b' \nkernel[blocksPerGrid, threadsPerBlock](a,b)\n# resulta = a.get()\n# resultb = b.get()\nprint(a,b)"
   ]
  },
  {
   "id": 2463,
   "type": "message",
   "date": "2019-11-13T16:47:39",
   "from": "یاری",
   "from_id": "user174088387",
   "reply_to_message_id": 2457,
   "text": "البته مشکل میتونه مربوط به نحوه فراخوانی کرنل هم باشه(اندازه گرید و اندازه بلاک مناسب با داده ها تعریف نشده باشه.)\nبهتر بود نحوه فراخوانی کرنل و کد کرنل رو هم میذاشتین."
  },
  {
   "id": 2536,
   "type": "message",
   "date": "2019-11-24T13:36:52",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 417,
   "height": 256,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nAnnounced at SC19, NVIDIA Magnum IO maximizes IO performance for multi-GPU, multi-node accelerated systems. Learn how this complements the capabilities of data management systems from IBMStorage.\n\n",
    {
     "type": "link",
     "text": "https://www.ibm.com/blogs/systems/accelerating-data-for-nvidia-gpus/"
    }
   ]
  },
  {
   "id": 2539,
   "type": "message",
   "date": "2019-11-26T21:44:58",
   "from": "haD",
   "from_id": "user126211582",
   "text": "آقا من سورس openmp یک دونه میخام. فقط ی سورس ناقصم باشه حلع. فقط ببینم سینتکسش چیه."
  },
  {
   "id": 2540,
   "type": "message",
   "date": "2019-11-26T21:45:03",
   "from": "haD",
   "from_id": "user126211582",
   "text": "چرا پیدانمیش"
  },
  {
   "id": 2545,
   "type": "message",
   "date": "2019-11-28T20:35:21",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "file": "(File not included. Change data exporting settings to download.)",
   "mime_type": "text/x-c++src",
   "text": ""
  },
  {
   "id": 2546,
   "type": "message",
   "date": "2019-11-28T20:35:22",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "file": "(File not included. Change data exporting settings to download.)",
   "mime_type": "text/x-c++src",
   "text": ""
  },
  {
   "id": 2547,
   "type": "message",
   "date": "2019-11-28T20:36:56",
   "from": "Milad Shahali",
   "from_id": "user129101046",
   "text": "امیدوارم نمونه کدهایی که گذاشتم مشکلتون رو حل کنه"
  },
  {
   "id": 2548,
   "type": "message",
   "date": "2019-11-29T00:36:59",
   "from": "haD",
   "from_id": "user126211582",
   "text": "خیلی ممنون و متشکر"
  },
  {
   "id": 2623,
   "type": "message",
   "date": "2019-12-03T11:39:15",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1279,
   "height": 1280,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\nNVIDIA Clara, a collection of developer toolkits aimed at accelerating compute, AI and advanced visualization, joins forces with NrgXnat, the most widely-used informatics platform for imaging research. \n\n",
    {
     "type": "link",
     "text": "https://news.developer.nvidia.com/nvidia-clara-and-xnat-join-forces-to-bring-ai-in-a-box-to-hospitals/?ncid=so-twit-39810#cid=ix03_so-twit_en-us"
    }
   ]
  },
  {
   "id": 2630,
   "type": "message",
   "date": "2019-12-03T12:46:46",
   "from": null,
   "from_id": "user982393899",
   "text": "سلام دوستان روز بخیر\n کسی openmp و کودا کار کرده؟\nیعنی  openmp  رو کنار کودا تو یک برنامه استفاده کرده باشه؟؟"
  },
  {
   "id": 2631,
   "type": "message",
   "date": "2019-12-03T13:00:55",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 2630,
   "text": "سلام  دوست عزیز سوالتون رو بپرسید."
  },
  {
   "id": 2632,
   "type": "message",
   "date": "2019-12-03T13:10:35",
   "from": null,
   "from_id": "user982393899",
   "text": "تو یک برنامه از  openmp  کنار کودا استفاده کردم  همه چی به ظاهر درسته ولی یه بخشی از خروجی هام اشتباهه مشکل از کجا میتونه باشه؟😥😥"
  },
  {
   "id": 2633,
   "type": "message",
   "date": "2019-12-03T13:15:28",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 2632,
   "text": "احتمالا مشکلتون در تعریف کرنل (تعداد thread ها و تعداد بلاک هاست) یا اینکه در دسترسی نخ ها درون کرنل مشکل دارید.  اگه ممکن کدتون رو بفرستید."
  },
  {
   "id": 2635,
   "type": "message",
   "date": "2019-12-03T15:09:32",
   "from": null,
   "from_id": "user982393899",
   "text": "کد کرنل یخورده زیاده نمیدونم دقیق کدوم بخشش رو لازم دارید.\nکسی از دوستان هست که بتونه با anydesk یا team viewer کمک کنه ممنون میشم.🙏🙏🙏🥺"
  },
  {
   "id": 2642,
   "type": "message",
   "date": "2019-12-03T16:08:00",
   "from": null,
   "from_id": "user950997009",
   "reply_to_message_id": 2635,
   "text": "سلام دوست عزیز"
  },
  {
   "id": 2643,
   "type": "message",
   "date": "2019-12-03T16:08:41",
   "from": null,
   "from_id": "user950997009",
   "text": "متاسفانه الان به تیم ویوور دسترسی ندارم"
  },
  {
   "id": 2644,
   "type": "message",
   "date": "2019-12-03T16:10:33",
   "from": null,
   "from_id": "user950997009",
   "text": "تا چند ساعت دیگه میرسم خونه\nلطفا پی وی پیام بدید\nیه تایم ست کنیم ببینم کدتون رو"
  },
  {
   "id": 2645,
   "type": "message",
   "date": "2019-12-03T16:11:25",
   "edited": "2019-12-03T16:11:38",
   "from": null,
   "from_id": "user950997009",
   "text": "کمکی از دستم بربیاد انجام میدم واستون"
  },
  {
   "id": 2646,
   "type": "message",
   "date": "2019-12-03T16:24:42",
   "from": null,
   "from_id": "user982393899",
   "reply_to_message_id": 2645,
   "text": "سپاس بی کران از لطفتون،  چشم پس من خدمتتون پیام میدم.🙏"
  },
  {
   "id": 2837,
   "type": "message",
   "date": "2019-12-11T17:34:20",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    " \n\n🖍 حافظه پین شده\n\nدسترسی مستقیم به حافظه که به آن DMA می گویند یکی از قابلیت های کامپیوترهای مدرن است و اجازه میدهد که زیرسیستم های سخت افزارهای خاصی از کامپیوتر بدون درگیر کردن سی پی یو به حافظه دسترسی داشته باشند. بدون DMA، زمانی که سی پی یو در حال استفاده از پورتهای خروجی و ورودی است، در تمام طول خواندن یا نوشتن مشغول می ماند و این باعث می شود که از انجام کارهای دیگر باز بماند. با DMA، سی پی یو عملیات انتقال را شروع می کند و در زمانی که عملیات انتقال در حال انجام شدن است عملیات دیگری را انجام میدهد و زمانی که عملیات انجام شد یک وقفه از کنترلر DMA دریافت می کند. این قابلیت زمانی مهم است که سی پی یو نمی تواند پابه پای نرخ انتقال داده کار کند، یا زمانی که انتقال داده نسبتأ کند است و سی پی یو لازم است که کار مهمی را انجام دهد. بسیاری از سیستم های سخت افزاری از جمله کارت های گرافیکی، کنترلر دیسک درایو، کارت های شبکه و کارتهای صدا از DMA استفاده می کنند.\nحافظه هاست تخصیص یافته با دستور malloc قابل صفحه بندی یا pagable است بدین معنا که صفحات حافظه مربوطه می توانند با حافظه های اطراف توسط هسته سیستم عامل حرکت کرده و سوئیچ شوند، به عنوان مثال می توان از سوئیچ فضا بر روی دیسک سخت نام برد. همچنین انتقال های  حافظه جی پی یو نیازمند عبور از گذرگاه PCI-E است. انتقال های PCI-E با موتورهای DMA بر روی جی پی یو مدیریت می شوند و مستقل از هسته سیستم عامل و سی پی یو کار می کنند. اگر هسته سیستم عامل صفحات حافظه درگیر را در چنین انتقال DMA بفرستد، داده های اشتباه منتقل خواهند شد. يقل خواهند شد. صفحات حافظه پین شده، هسته سیستم عامل را از انتقال آنها به اطراف باز داشته و آنها را برای انتقال DMA قابل استفاده می کند."
   ]
  },
  {
   "id": 2839,
   "type": "message",
   "date": "2019-12-11T17:37:40",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1024,
   "height": 541,
   "text": [
    {
     "type": "hashtag",
     "text": "#آموزش"
    },
    "\n\n🖍 حافظه پین شده\n\nدر حالت حافظه پین نشده یا حافظه pagable، حافظه  هاست اختصاص داده شده با malloc از طریق یک حافظه بافر پین شده تحت کنترل درایور کودا مدیریت می شود. در این حات هیچ  کپی ناهمگام حافظه ای امکان پذیر نبوده (تعامل سی پی یو برای مدیریت خط لوله ضروری است ) همچنین تاخیر بیشتر و پهنای باند پایین تر نسبت به انتقال های DMA داریم .\nاما در حالت استفاده از حافظه هاست پین شده، کپی های ناهمگام  حافظه را قادر ساخته و همچنین سبب کاهش زمان تأخیر و افزایش پهنای باند می شود .\nدو راه برای دستیابی به حافظه هاست پین شده وجود دارد:\n\n1️⃣ استفاده از cudaHostAlloc / cudaFreeHost برای تخصیص حافظه جدید.\n\n2️⃣ استفاده از cudaHostRegister / cudaHostUnregister برای حافظه پین شده بعد از تخصیص."
   ]
  },
  {
   "id": 2840,
   "type": "message",
   "date": "2019-12-11T18:50:19",
   "edited": "2019-12-11T18:52:21",
   "from": null,
   "from_id": "user673890296",
   "text": "سلام دوستان\nکسی هست که بتونه یه الگوریتم رو به صورت سری و چند نخی و با کودا پیاده سازی کنه؟؟"
  },
  {
   "id": 2841,
   "type": "message",
   "date": "2019-12-11T19:35:41",
   "from": null,
   "from_id": "user950997009",
   "reply_to_message_id": 2840,
   "text": "سلام\nالگوریتمتونو واسم تو پی وی بفرستید.\nکمکی از دستم بر بیاد انجام میدم واستون"
  },
  {
   "id": 2842,
   "type": "message",
   "date": "2019-12-11T19:40:22",
   "from": null,
   "from_id": "user673890296",
   "reply_to_message_id": 2841,
   "text": "خیلی ممنون🙏"
  },
  {
   "id": 2845,
   "type": "message",
   "date": "2019-12-11T22:25:25",
   "from": "Moein",
   "from_id": "user751442599",
   "text": "سلام دوستان کودا تابع آماده داره برای اینکه کد اسکی مربوط به اعداد صحیح رو تبدیل به عدد صحیح بکنه؟ مثلا کد اسکی عدد 1 میشه 49، عدد 49 رو بگیره برامون عدد 1 رو برگردونه"
  },
  {
   "id": 2848,
   "type": "message",
   "date": "2019-12-11T22:45:36",
   "edited": "2019-12-11T22:45:51",
   "from": "Moein",
   "from_id": "user751442599",
   "reply_to_message_id": 2845,
   "text": "توی c++ تابعی به اسم  stoi() برای تبدیل رشته به عدد صحیح وجود داره، معادل این رو توی کودا میخام،اگه کسی کمک کنه ممنون میشم"
  },
  {
   "id": 2857,
   "type": "message",
   "date": "2019-12-12T15:57:46",
   "from": "یاری",
   "from_id": "user174088387",
   "reply_to_message_id": 2845,
   "text": "سلام\nفکر نکنم تابع آماده ای برای این کار باشه.\nاما اگه شما فقط می خواین کد اسکی اعداد صحیح رو به عدد صحیح تبدیل کنین، کافیه 48 تا ازش کم کنید تا به عدد صحیح برسید."
  },
  {
   "id": 2858,
   "type": "message",
   "date": "2019-12-12T15:58:01",
   "from": "یاری",
   "from_id": "user174088387",
   "reply_to_message_id": 2848,
   "file": "(File not included. Change data exporting settings to download.)",
   "mime_type": "text/x-c++src",
   "text": ""
  },
  {
   "id": 2859,
   "type": "message",
   "date": "2019-12-12T15:58:42",
   "from": "یاری",
   "from_id": "user174088387",
   "reply_to_message_id": 2858,
   "text": "برای سوال بعدی هم، این کد رو به راحتی می تونین تو کودا پیاده سازی کنین."
  },
  {
   "id": 2860,
   "type": "message",
   "date": "2019-12-12T15:58:57",
   "from": "یاری",
   "from_id": "user174088387",
   "text": "بازم فکر نکنم تابع آماده داشته باشه."
  },
  {
   "id": 2861,
   "type": "message",
   "date": "2019-12-12T16:11:16",
   "from": "یاری",
   "from_id": "user174088387",
   "reply_to_message_id": 2858,
   "text": "int strToInt(char *s)\n{\n    int n = 0;\n    for (int i = 0; s[i]!='\\0'; i++)\n    {\n        n *= 10;\n        n += ((int)s[i] - 48);\n    }\n return n;\n}"
  },
  {
   "id": 2862,
   "type": "message",
   "date": "2019-12-12T20:11:34",
   "from": "Moein",
   "from_id": "user751442599",
   "reply_to_message_id": 2857,
   "text": "دستت درد نکنه همون کارو کردم،البته من باقی ماند تقسیم کد اسکی بر 12 رو محاسبه کردم میشه خود عدد صحیح"
  },
  {
   "id": 2863,
   "type": "message",
   "date": "2019-12-12T20:12:05",
   "from": "Moein",
   "from_id": "user751442599",
   "text": "حل شد دیشب ممنون از راهنماییت دوست عزیز👍"
  },
  {
   "id": 2864,
   "type": "message",
   "date": "2019-12-12T20:53:38",
   "from": "haD",
   "from_id": "user126211582",
   "text": "دوستان در ویژوال استدیو 2019 چرا نمیتونم openmp رو فعال کنم هیچ ترفندی وجود نداره ؟"
  },
  {
   "id": 2865,
   "type": "message",
   "date": "2019-12-12T20:58:45",
   "from": "haD",
   "from_id": "user126211582",
   "text": "ساپورت نمیکنه میدونم. ولی یک راهی باید باشه. اخه کتابخونه شو دازه"
  },
  {
   "id": 2866,
   "type": "message",
   "date": "2019-12-13T00:58:11",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 2840,
   "text": "دوست گرامی لطفا درخواست پروژه مطرح نکنید. مشکلتون رو بیان کنید سایر دوستان تا جایی که بشه کمکتون می کنند. ممنون."
  },
  {
   "id": 2890,
   "type": "message",
   "date": "2019-12-13T15:39:43",
   "from": null,
   "from_id": "user950997009",
   "reply_to_message_id": 2866,
   "text": "ببخشید دوست عزیز\nمن با قوانین گروه آشنا نبودم\nالبته حتما موارد مهمی که با دوستان بهشون می رسیم رو هم تو گروه اعلام میکنم"
  },
  {
   "id": 2919,
   "type": "message",
   "date": "2019-12-14T17:18:36",
   "from": null,
   "from_id": "user950997009",
   "reply_to_message_id": 2865,
   "text": [
    "سلام دوست عزیز\nلینک زیر رو بررسی بکنید\nاحتمالا مشکلتونو بر طرف میکنه\n",
    {
     "type": "link",
     "text": "https://docs.microsoft.com/en-us/cpp/build/reference/openmp-enable-openmp-2-0-support?view=vs-2019"
    },
    ""
   ]
  },
  {
   "id": 2920,
   "type": "message",
   "date": "2019-12-14T19:01:53",
   "from": "haD",
   "from_id": "user126211582",
   "reply_to_message_id": 2919,
   "text": "از بابت توجهت خیلی ممنون دوست من."
  },
  {
   "id": 2965,
   "type": "message",
   "date": "2019-12-16T12:46:14",
   "from": null,
   "from_id": "user950997009",
   "reply_to_message_id": 2920,
   "text": "اختیار دارید\nخواهش میکنم"
  },
  {
   "id": 3026,
   "type": "message",
   "date": "2019-12-18T23:24:48",
   "from": null,
   "from_id": "user950997009",
   "file": "(File not included. Change data exporting settings to download.)",
   "mime_type": "text/plain",
   "text": ""
  },
  {
   "id": 3029,
   "type": "message",
   "date": "2019-12-18T23:27:02",
   "from": null,
   "from_id": "user950997009",
   "reply_to_message_id": 2890,
   "text": "دوستان این مثال ساده استفاده کتابخانه OpenMP در کنار کودا هست"
  },
  {
   "id": 3030,
   "type": "message",
   "date": "2019-12-18T23:28:32",
   "from": null,
   "from_id": "user950997009",
   "file": "(File not included. Change data exporting settings to download.)",
   "mime_type": "text/plain",
   "text": ""
  },
  {
   "id": 3031,
   "type": "message",
   "date": "2019-12-18T23:30:08",
   "from": null,
   "from_id": "user950997009",
   "reply_to_message_id": 3030,
   "text": "این مثال هم کارایی  بالای استفاده از جریان ها و اجرای همپوشان کرنل و انتقال داده ها و مخصوصا استفاده از چند جریانی  رو نشون میده."
  },
  {
   "id": 3306,
   "type": "message",
   "date": "2019-12-31T10:33:46",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 618,
   "height": 417,
   "text": [
    {
     "type": "hashtag",
     "text": "#news"
    },
    "\n\n🔍  To achieve 30-50x faster processing from next generation sequencing to variant calling, parabricks  and NVIDIA  team up to offer the NVIDIA Parabricks Genomics Analysis Toolkit.\n\n🖍 Parabricks is built using NVIDIA CUDA-X and benefits from CUDA, cuDNN and TensorRT inference software and runs on NVIDIA entire computing platform from NVIDIA T4 to DGX to cloud GPU instances."
   ]
  },
  {
   "id": 4139,
   "type": "message",
   "date": "2020-06-20T23:00:36",
   "from": "630N",
   "from_id": "user133189412",
   "forwarded_from": "برنامه نویسان",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 1280,
   "height": 852,
   "text": [
    "نور گوشی همراه در شب باعث سرطان چشم میشود سرطان چشم از مضرات استفاده مداوم از گوشی همراه در شب است !\n\nزمانیکه فشار زیاد بر کره چشم خود احساس میکنید باید به پزشک مراجعه کنید\n\n🌐مرجع تخصصی برنامه نویسان\n\n🆔 ",
    {
     "type": "mention",
     "text": "@Barnamenevisan_org"
    },
    ""
   ]
  },
  {
   "id": 4142,
   "type": "message",
   "date": "2020-10-24T00:25:37",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "file": "(File not included. Change data exporting settings to download.)",
   "thumbnail": "(File not included. Change data exporting settings to download.)",
   "media_type": "video_file",
   "mime_type": "video/mp4",
   "duration_seconds": 30,
   "width": 640,
   "height": 360,
   "text": "🟩◼️🟩  GeForce RTX 3080🟩◼️🟩 \n\n✔️   The GeForce RTX™ 3080 delivers the ultra performance that gamers crave, powered by Ampere NVIDIA’s 2nd gen RTX architecture. It’s built with enhanced RT Cores and Tensor Cores, new streaming multiprocessors, and superfast G6X memory for an amazing gaming experience."
  },
  {
   "id": 4143,
   "type": "message",
   "date": "2020-10-24T00:25:37",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 869,
   "height": 512,
   "text": "✅ Performance\n\n🟢RTX 3080     ⚪️RTX 2080    🟡 GTX 108"
  },
  {
   "id": 4144,
   "type": "message",
   "date": "2020-10-24T00:25:37",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "forwarded_from": "CUDA",
   "photo": "(File not included. Change data exporting settings to download.)",
   "width": 984,
   "height": 517,
   "text": "🔴 GEFORCE RTX 3080 SPECS"
  },
  {
   "id": 4146,
   "type": "message",
   "date": "2021-02-26T23:59:14",
   "edited": "2021-02-26T23:59:26",
   "from": "M Sadeghi",
   "from_id": "user119511961",
   "reply_to_message_id": 4145,
   "text": "سلام نیرو توی چه زمینه ای از هوش میخان؟"
  },
  {
   "id": 4148,
   "type": "message",
   "date": "2021-09-18T15:45:16",
   "from": "MohammadJafar Karimi",
   "from_id": "user97306990",
   "text": "سلام برهمه دوستان\nسوال درمورد سی پی یو داشتم\nمختصرو مفید  AMD or Intel 😁\nمیخواهیم یه سیستم پردازش اسمبل کنیم کدوم به نظرتون بهتره برای کارهای پردازشی ؟"
  },
  {
   "id": 4149,
   "type": "message",
   "date": "2021-09-19T10:25:50",
   "from": "MhmdRza",
   "from_id": "user168601906",
   "reply_to_message_id": 4148,
   "text": "بله."
  },
  {
   "id": 4150,
   "type": "message",
   "date": "2021-09-19T11:06:36",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "reply_to_message_id": 4148,
   "text": "سلام \nتا دو سه سال اخیر این انتخاب مشخص بود الان یک مقدار سخت شده باید جزییات کارتونو بدونید در کل Amd از لحاظ قیمت مناسب تره، اکثرا هم تعداد core هاش بیشتره ولی قدرت core اینتل بهتره پس اینتل  عملکرد کلی بهتری داره اما مولتی تسکینگ و رندرینگ amd به واسطه core های بیشتر مناسب تره.\nتا جایی که میدونم اینتل برای اور کلاک کردن مدل های محدودی داره ولی بهتره البته اگه حاضر باشید اور کلاک کنید.  کلا اگه مولتی تسکینگ و رندرینگ در نظر دارید  amd بهتره و مابقی موارد  intel بهتره."
  },
  {
   "id": 4151,
   "type": "message",
   "date": "2021-09-19T11:08:16",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "text": "از این سایت قابلیت هارو مقایسه کنید."
  },
  {
   "id": 4152,
   "type": "message",
   "date": "2021-09-19T11:08:22",
   "from": "Hamid Khorshidian",
   "from_id": "user121569222",
   "text": [
    {
     "type": "link",
     "text": "https://www.cpubenchmark.net/singleCompare.php"
    }
   ]
  },
  {
   "id": 4153,
   "type": "message",
   "date": "2021-09-19T11:46:09",
   "from": "MohammadJafar Karimi",
   "from_id": "user97306990",
   "reply_to_message_id": 4150,
   "text": "👍\nدقیقا توی این مدت اخیر هست که یه کمی باید در موردش تحقیقات بیشتری کرد"
  },
  {
   "id": 4154,
   "type": "message",
   "date": "2021-09-19T11:46:15",
   "from": "MohammadJafar Karimi",
   "from_id": "user97306990",
   "text": "کسی تجربه کار با AMD برای کارهای دیپ و مالتی تسکینگ را داره؟"
  }
 ]
}